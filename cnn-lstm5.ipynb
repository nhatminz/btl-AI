{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:38.704444Z",
     "iopub.status.busy": "2025-04-29T03:14:38.703768Z",
     "iopub.status.idle": "2025-04-29T03:14:43.994397Z",
     "shell.execute_reply": "2025-04-29T03:14:43.993164Z",
     "shell.execute_reply.started": "2025-04-29T03:14:38.704381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GDAL in /usr/local/lib/python3.11/dist-packages (3.6.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install GDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:43.996902Z",
     "iopub.status.busy": "2025-04-29T03:14:43.996560Z",
     "iopub.status.idle": "2025-04-29T03:14:52.535400Z",
     "shell.execute_reply": "2025-04-29T03:14:52.534552Z",
     "shell.execute_reply.started": "2025-04-29T03:14:43.996874Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.536729Z",
     "iopub.status.busy": "2025-04-29T03:14:52.536280Z",
     "iopub.status.idle": "2025-04-29T03:14:52.546300Z",
     "shell.execute_reply": "2025-04-29T03:14:52.545327Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.536705Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.550009Z",
     "iopub.status.busy": "2025-04-29T03:14:52.549517Z",
     "iopub.status.idle": "2025-04-29T03:14:52.666765Z",
     "shell.execute_reply": "2025-04-29T03:14:52.665506Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.549970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Đặt seed để tái lập kết quả\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Định nghĩa các hằng số và đường dẫn\n",
    "BASE_PATH = \"/kaggle/input/btl-ai/DATA_SV\"\n",
    "HIMA_PATH = os.path.join(BASE_PATH, \"Hima\")\n",
    "ERA5_PATH = os.path.join(BASE_PATH, \"ERA5\")\n",
    "PRECIP_PATH = os.path.join(BASE_PATH, \"Precipitation/Radar\")\n",
    "OUTPUT_PATH = \"/kaggle/working/output/\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.668250Z",
     "iopub.status.busy": "2025-04-29T03:14:52.667907Z",
     "iopub.status.idle": "2025-04-29T03:14:52.674841Z",
     "shell.execute_reply": "2025-04-29T03:14:52.673717Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.668215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HIMA_BANDS = ['B04B', 'B05B', 'B06B', 'B09B', 'B10B', 'B11B', 'B12B', 'B14B', 'B16B', 'I2B', 'I4B', 'IRB', 'VSB', 'WVB']  # 14 band\n",
    "ERA5_PARAMS = ['CAPE', 'CIN', 'EWSS', 'IE', 'ISOR', 'KX', 'PEV', 'R250', 'R500', 'R850', 'SLHF', 'SLOR', 'SSHF', 'TCLW', 'TCW', 'TCWV', 'U250', 'U850', 'V250', 'V850']  # 20 tham số\n",
    "HEIGHT, WIDTH = 90, 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.676341Z",
     "iopub.status.busy": "2025-04-29T03:14:52.676015Z",
     "iopub.status.idle": "2025-04-29T03:14:52.694568Z",
     "shell.execute_reply": "2025-04-29T03:14:52.693576Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.676317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Hàm xử lý dữ liệu\n",
    "# Hàm đọc file GeoTIFF\n",
    "def read_geotiff(file_path):\n",
    "    try:\n",
    "        ds = gdal.Open(file_path)\n",
    "        band = ds.GetRasterBand(1)\n",
    "        data = band.ReadAsArray()\n",
    "        ds = None\n",
    "        if data.shape != (HEIGHT, WIDTH):\n",
    "            print(f\"Invalid shape {data.shape} for file {file_path}, expected ({HEIGHT}, {WIDTH})\")\n",
    "            return None\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.695997Z",
     "iopub.status.busy": "2025-04-29T03:14:52.695659Z",
     "iopub.status.idle": "2025-04-29T03:14:52.715913Z",
     "shell.execute_reply": "2025-04-29T03:14:52.714763Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.695970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm phân tích thời gian từ tên file\n",
    "def parse_datetime_from_filename(filename, data_type):\n",
    "    try:\n",
    "        if data_type == \"Hima\":\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) < 2:\n",
    "                return None\n",
    "            time_part = parts[1].split('_TB.tif')[0]\n",
    "            time_part = time_part.replace('.Z', '')\n",
    "            dt = datetime.strptime(time_part, '%Y%m%d%H%M')\n",
    "        elif data_type == \"ERA5\":\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) < 2:\n",
    "                return None\n",
    "            time_part = parts[1].replace('.tif', '')\n",
    "            dt = datetime.strptime(time_part, '%Y%m%d%H%M%S')\n",
    "        elif data_type == \"Radar\":\n",
    "            time_part = filename.split('_')[1].replace('.tif', '')\n",
    "            dt = datetime.strptime(time_part, '%Y%m%d%H%M%S')\n",
    "        else:\n",
    "            return None\n",
    "        return dt.replace(minute=0, second=0, microsecond=0)\n",
    "    except Exception as e:\n",
    "        global error_count\n",
    "        if error_count < 5:\n",
    "            print(f\"Error parsing datetime from {filename} (type {data_type}): {e}\")\n",
    "            error_count += 1\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.717287Z",
     "iopub.status.busy": "2025-04-29T03:14:52.716923Z",
     "iopub.status.idle": "2025-04-29T03:14:52.742036Z",
     "shell.execute_reply": "2025-04-29T03:14:52.741097Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.717247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "error_count = 0\n",
    "\n",
    "# Hàm thu thập file\n",
    "def collect_files(base_path, expected_subdirs=None, data_type=None):\n",
    "    files_dict = {}\n",
    "    file_count = 0\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.tif'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                dt = parse_datetime_from_filename(file, data_type)\n",
    "                if dt is None:\n",
    "                    continue\n",
    "                file_count += 1\n",
    "                if expected_subdirs:\n",
    "                    subdir = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(file_path)))))\n",
    "                    if dt not in files_dict:\n",
    "                        files_dict[dt] = {}\n",
    "                    files_dict[dt][subdir] = file_path\n",
    "                else:\n",
    "                    files_dict[dt] = file_path\n",
    "    print(f\"Found {file_count} files in {base_path}\")\n",
    "    return files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.743541Z",
     "iopub.status.busy": "2025-04-29T03:14:52.743197Z",
     "iopub.status.idle": "2025-04-29T03:14:52.766691Z",
     "shell.execute_reply": "2025-04-29T03:14:52.765594Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.743505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm xử lý dữ liệu thiếu và chuẩn hóa\n",
    "def preprocess_data(data, data_type):\n",
    "    if data is None:\n",
    "        return None\n",
    "    # Xử lý giá trị không hợp lệ\n",
    "    data = np.where(np.isinf(data) | np.isnan(data) | (data == -9999), 0, data)\n",
    "    if data_type == \"Radar\":\n",
    "        # Log transformation cho radar\n",
    "        data = np.log1p(np.maximum(data, 0))  # log(1 + x)\n",
    "    else:\n",
    "        # Min-max scaling cho Himawari và ERA5\n",
    "        data_min, data_max = np.min(data), np.max(data)\n",
    "        if data_max > data_min:\n",
    "            data = (data - data_min) / (data_max - data_min)\n",
    "        else:\n",
    "            data = np.zeros_like(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.770582Z",
     "iopub.status.busy": "2025-04-29T03:14:52.770253Z",
     "iopub.status.idle": "2025-04-29T03:14:52.790584Z",
     "shell.execute_reply": "2025-04-29T03:14:52.789301Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.770559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# FocalLoss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "    def forward(self, y_pred, y_true):\n",
    "        mse_loss = nn.functional.mse_loss(y_pred, y_true, reduction='none')\n",
    "        pt = torch.exp(-mse_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * mse_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.792446Z",
     "iopub.status.busy": "2025-04-29T03:14:52.791975Z",
     "iopub.status.idle": "2025-04-29T03:14:52.810798Z",
     "shell.execute_reply": "2025-04-29T03:14:52.809850Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.792339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_time_sequences(hima_files, era5_files, precip_files, common_datetimes, seq_len=3, max_gap_hours=3):\n",
    "    X, y = [], []\n",
    "    discontinuity_count = 0\n",
    "    missing_data_count = 0\n",
    "    \n",
    "    for i in range(seq_len-1, len(common_datetimes)):\n",
    "        dt = common_datetimes[i]\n",
    "        sequence = []\n",
    "        valid_sequence = True\n",
    "        \n",
    "        for j in range(seq_len-1, -1, -1):  # t-2, t-1, t (nếu seq_len=3)\n",
    "            target_dt = dt - timedelta(hours=j)\n",
    "            # Tìm thời điểm gần nhất trong common_datetimes\n",
    "            dt_diffs = [(abs((target_dt - dt_i).total_seconds()), dt_i) for dt_i in common_datetimes]\n",
    "            dt_diffs.sort()\n",
    "            closest_dt, closest_dt_diff = dt_diffs[0][1], dt_diffs[0][0] / 3600  # Chuyển thành giờ\n",
    "            \n",
    "            # Kiểm tra khoảng cách thời gian\n",
    "            if closest_dt_diff > max_gap_hours:\n",
    "                valid_sequence = False\n",
    "                discontinuity_count += 1\n",
    "                break\n",
    "            \n",
    "            # Đọc dữ liệu Himawari\n",
    "            hima_data = []\n",
    "            for band in HIMA_BANDS:\n",
    "                file_path = hima_files.get(closest_dt, {}).get(band)\n",
    "                if not file_path:\n",
    "                    valid_sequence = False\n",
    "                    missing_data_count += 1\n",
    "                    break\n",
    "                data = read_geotiff(file_path)\n",
    "                data = preprocess_data(data, \"Hima\")\n",
    "                if data is None:\n",
    "                    valid_sequence = False\n",
    "                    missing_data_count += 1\n",
    "                    break\n",
    "                hima_data.append(data)\n",
    "            if not valid_sequence:\n",
    "                break\n",
    "            hima_data = np.stack(hima_data, axis=-1)\n",
    "            \n",
    "            # Đọc dữ liệu ERA5\n",
    "            era5_data = []\n",
    "            for param in ERA5_PARAMS:\n",
    "                file_path = era5_files.get(closest_dt, {}).get(param)\n",
    "                if not file_path:\n",
    "                    valid_sequence = False\n",
    "                    missing_data_count += 1\n",
    "                    break\n",
    "                data = read_geotiff(file_path)\n",
    "                data = preprocess_data(data, \"ERA5\")\n",
    "                if data is None:\n",
    "                    valid_sequence = False\n",
    "                    missing_data_count += 1\n",
    "                    break\n",
    "                era5_data.append(data)\n",
    "            if not valid_sequence:\n",
    "                break\n",
    "            era5_data = np.stack(era5_data, axis=-1)\n",
    "            \n",
    "            combined = np.concatenate([hima_data, era5_data], axis=-1)\n",
    "            sequence.append(combined)\n",
    "        \n",
    "        if not valid_sequence:\n",
    "            continue\n",
    "        \n",
    "        # Đọc radar (ground truth)\n",
    "        radar_file = precip_files.get(dt)\n",
    "        if not radar_file:\n",
    "            missing_data_count += 1\n",
    "            continue\n",
    "        radar_data = read_geotiff(radar_file)\n",
    "        radar_data = preprocess_data(radar_data, \"Radar\")\n",
    "        if radar_data is None:\n",
    "            missing_data_count += 1\n",
    "            continue\n",
    "        \n",
    "        sequence = np.stack(sequence, axis=0)  # (seq_len, 90, 250, 34)\n",
    "        X.append(sequence)\n",
    "        y.append(radar_data)  # (90, 250)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.transpose(0, 1, 4, 2, 3)  # (samples, seq_len, 34, 90, 250)\n",
    "    \n",
    "    print(f\"Skipped due to discontinuity (gap > {max_gap_hours} hours): {discontinuity_count}\")\n",
    "    print(f\"Skipped due to missing data: {missing_data_count}\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.812289Z",
     "iopub.status.busy": "2025-04-29T03:14:52.811959Z",
     "iopub.status.idle": "2025-04-29T03:14:52.834547Z",
     "shell.execute_reply": "2025-04-29T03:14:52.833622Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.812254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Định nghĩa lớp ConvLSTMCell tùy chỉnh\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels + out_channels, 4 * out_channels, kernel_size,\n",
    "            padding=padding, bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        # x: (batch, in_channels, height, width)\n",
    "        # h_prev, c_prev: (batch, out_channels, height, width)\n",
    "        combined = torch.cat([x, h_prev], dim=1)  # (batch, in_channels + out_channels, height, width)\n",
    "        conv_out = self.conv(combined)  # (batch, 4 * out_channels, height, width)\n",
    "        i, f, o, g = torch.chunk(conv_out, 4, dim=1)  # Mỗi cái: (batch, out_channels, height, width)\n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        o = torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "        c_next = f * c_prev + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.835738Z",
     "iopub.status.busy": "2025-04-29T03:14:52.835486Z",
     "iopub.status.idle": "2025-04-29T03:14:52.859551Z",
     "shell.execute_reply": "2025-04-29T03:14:52.858295Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.835720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Định nghĩa lớp ConvLSTM2d\n",
    "class ConvLSTM2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super(ConvLSTM2d, self).__init__()\n",
    "        self.cell = ConvLSTMCell(in_channels, out_channels, kernel_size, padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Kiểm tra số chiều của đầu vào\n",
    "        if len(x.size()) == 5:\n",
    "            # x: (batch, seq_len, channels, height, width)\n",
    "            batch, seq_len, channels, height, width = x.size()\n",
    "            is_sequence = True\n",
    "        elif len(x.size()) == 4:\n",
    "            # x: (batch, channels, height, width)\n",
    "            batch, channels, height, width = x.size()\n",
    "            seq_len = 1\n",
    "            x = x.unsqueeze(1)  # Thêm chiều seq_len: (batch, 1, channels, height, width)\n",
    "            is_sequence = False\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 4 or 5 dimensions, got {len(x.size())}\")\n",
    "\n",
    "        out_channels = self.cell.out_channels\n",
    "        h = torch.zeros(batch, out_channels, height, width, device=x.device)\n",
    "        c = torch.zeros(batch, out_channels, height, width, device=x.device)\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :, :, :]  # (batch, channels, height, width)\n",
    "            h, c = self.cell(x_t, h, c)\n",
    "            outputs.append(h)\n",
    "        output = outputs[-1] if is_sequence else h\n",
    "        return output, (h, c)  # Trả về output cuối và trạng thái"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.860757Z",
     "iopub.status.busy": "2025-04-29T03:14:52.860513Z",
     "iopub.status.idle": "2025-04-29T03:14:52.889254Z",
     "shell.execute_reply": "2025-04-29T03:14:52.887951Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.860740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm huấn luyện mô hình\n",
    "def train_model(model, train_loader, val_loader, epochs=30, patience=7):\n",
    "    criterion = FocalLoss(gamma=2.0, alpha=0.25)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                output = model(X_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.890478Z",
     "iopub.status.busy": "2025-04-29T03:14:52.890140Z",
     "iopub.status.idle": "2025-04-29T03:14:52.913499Z",
     "shell.execute_reply": "2025-04-29T03:14:52.912587Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.890456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Định nghĩa mô hình ConvLSTM\n",
    "class ConvLSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "        self.convlstm1 = ConvLSTM2d(in_channels=34, out_channels=64, kernel_size=(5, 5), padding=(2, 2))\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.convlstm2 = ConvLSTM2d(in_channels=64, out_channels=32, kernel_size=(5, 5), padding=(2, 2))\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.conv = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len=5, channels=34, height=90, width=250)\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        x, _ = self.convlstm1(x)  # (batch, 64, height, width)\n",
    "        x = self.bn1(x)\n",
    "        print(f\"After convlstm1: {x.shape}\")\n",
    "        x, _ = self.convlstm2(x)  # (batch, 32, height, width)\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv(x)  # (batch, 1, height, width)\n",
    "        x = self.relu(x)\n",
    "        return x.squeeze(1)  # (batch, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.914939Z",
     "iopub.status.busy": "2025-04-29T03:14:52.914633Z",
     "iopub.status.idle": "2025-04-29T03:14:52.940679Z",
     "shell.execute_reply": "2025-04-29T03:14:52.939653Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.914909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm tính chỉ số đánh giá\n",
    "def evaluate_model(y_true, y_pred, threshold=0.0):\n",
    "    y_true = y_true.reshape(-1)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    corr = np.corrcoef(y_true, y_pred)[0, 1] if np.std(y_true) > 0 and np.std(y_pred) > 0 else 0\n",
    "\n",
    "    y_true_bin = (y_true > threshold).astype(int)\n",
    "    y_pred_bin = (y_pred > threshold).astype(int)\n",
    "    hits = np.sum((y_true_bin == 1) & (y_pred_bin == 1))\n",
    "    misses = np.sum((y_true_bin == 1) & (y_pred_bin == 0))\n",
    "    false_alarms = np.sum((y_true_bin == 0) & (y_pred_bin == 1))\n",
    "    true_negatives = np.sum((y_true_bin == 0) & (y_pred_bin == 0))\n",
    "    total = hits + misses + false_alarms + true_negatives\n",
    "\n",
    "    accuracy = (hits + true_negatives) / total if total > 0 else 0\n",
    "    csi = hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0\n",
    "    far = false_alarms / (hits + false_alarms) if (hits + false_alarms) > 0 else 0\n",
    "    hss = (2 * (hits * true_negatives - misses * false_alarms)) / \\\n",
    "          ((hits + misses) * (misses + true_negatives) + (hits + false_alarms) * (false_alarms + true_negatives)) \\\n",
    "          if ((hits + misses) * (misses + true_negatives) + (hits + false_alarms) * (false_alarms + true_negatives)) > 0 else 0\n",
    "    ets = ((hits - ((hits + misses) * (hits + false_alarms) / total)) / \\\n",
    "           (hits + misses + false_alarms - ((hits + misses) * (hits + false_alarms) / total))) \\\n",
    "          if (hits + misses + false_alarms - ((hits + misses) * (hits + false_alarms) / total)) > 0 else 0\n",
    "\n",
    "    return {'rmse': rmse, 'corr': corr, 'accuracy': accuracy, 'csi': csi, 'far': far, 'hss': hss, 'ets': ets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.942024Z",
     "iopub.status.busy": "2025-04-29T03:14:52.941686Z",
     "iopub.status.idle": "2025-04-29T03:14:52.966390Z",
     "shell.execute_reply": "2025-04-29T03:14:52.965393Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.942002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm vẽ scatter plot\n",
    "def plot_scatter(y_true, y_pred, output_path):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_true.flatten(), y_pred.flatten(), alpha=0.5)\n",
    "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
    "    plt.xlabel('Ground Truth (mm/h)')\n",
    "    plt.ylabel('Predicted (mm/h)')\n",
    "    plt.title('Scatter Plot: Predicted vs Ground Truth')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.967712Z",
     "iopub.status.busy": "2025-04-29T03:14:52.967306Z",
     "iopub.status.idle": "2025-04-29T03:14:52.993221Z",
     "shell.execute_reply": "2025-04-29T03:14:52.992095Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.967680Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm hiển thị bản đồ\n",
    "def plot_rainfall_map(y_true, y_pred, output_path):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax1.set_title('Ground Truth')\n",
    "    ax2.set_title('Prediction')\n",
    "    for ax, data in [(ax1, y_true), (ax2, y_pred)]:\n",
    "        ax.coastlines()\n",
    "        ax.add_feature(cfeature.BORDERS)\n",
    "        im = ax.imshow(data, cmap='Blues', origin='upper', transform=ccrs.PlateCarree())\n",
    "        plt.colorbar(im, ax=ax, label='Rainfall (mm/h)')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:52.994897Z",
     "iopub.status.busy": "2025-04-29T03:14:52.994557Z",
     "iopub.status.idle": "2025-04-29T03:14:53.015258Z",
     "shell.execute_reply": "2025-04-29T03:14:53.014473Z",
     "shell.execute_reply.started": "2025-04-29T03:14:52.994870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm lưu GeoTIFF\n",
    "def save_geotiff(data, output_path, reference_file):\n",
    "    ds = gdal.Open(reference_file)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    out_ds = driver.Create(output_path, WIDTH, HEIGHT, 1, gdal.GDT_Float32)\n",
    "    out_ds.SetGeoTransform(ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds.GetProjection())\n",
    "    out_band = out_ds.GetRasterBand(1)\n",
    "    out_band.WriteArray(data)\n",
    "    out_band.FlushCache()\n",
    "    out_ds = None\n",
    "    ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:14:53.016675Z",
     "iopub.status.busy": "2025-04-29T03:14:53.016339Z",
     "iopub.status.idle": "2025-04-29T03:15:42.286499Z",
     "shell.execute_reply": "2025-04-29T03:15:42.285648Z",
     "shell.execute_reply.started": "2025-04-29T03:14:53.016642Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Himawari files...\n",
      "Found 1438 files in /kaggle/input/btl-ai/DATA_SV/Hima/B04B\n",
      "Found 1361 files in /kaggle/input/btl-ai/DATA_SV/Hima/B05B\n",
      "Found 1158 files in /kaggle/input/btl-ai/DATA_SV/Hima/B06B\n",
      "Found 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B09B\n",
      "Found 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B10B\n",
      "Found 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B11B\n",
      "Found 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B12B\n",
      "Found 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/B14B\n",
      "Found 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/B16B\n",
      "Found 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/I2B\n",
      "Found 2673 files in /kaggle/input/btl-ai/DATA_SV/Hima/I4B\n",
      "Found 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/IRB\n",
      "Found 1448 files in /kaggle/input/btl-ai/DATA_SV/Hima/VSB\n",
      "Found 2774 files in /kaggle/input/btl-ai/DATA_SV/Hima/WVB\n"
     ]
    }
   ],
   "source": [
    "# Bắt đầu chương trình\n",
    "print(\"Collecting Himawari files...\")\n",
    "hima_files = {}\n",
    "for band in HIMA_BANDS:\n",
    "    band_path = os.path.join(HIMA_PATH, band)\n",
    "    if not os.path.exists(band_path):\n",
    "        print(f\"Directory not found: {band_path}\")\n",
    "        continue\n",
    "    band_files = collect_files(band_path, expected_subdirs=HIMA_BANDS, data_type=\"Hima\")\n",
    "    for dt, paths in band_files.items():\n",
    "        if dt not in hima_files:\n",
    "            hima_files[dt] = {}\n",
    "        hima_files[dt][band] = paths[band]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:15:42.287845Z",
     "iopub.status.busy": "2025-04-29T03:15:42.287512Z",
     "iopub.status.idle": "2025-04-29T03:17:15.860294Z",
     "shell.execute_reply": "2025-04-29T03:17:15.859293Z",
     "shell.execute_reply.started": "2025-04-29T03:15:42.287802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ERA5 files...\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/CAPE\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/CIN\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/EWSS\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/IE\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/ISOR\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/KX\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/PEV\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/R250\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/R500\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/R850\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/SLHF\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/SLOR\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/SSHF\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/TCLW\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/TCW\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/TCWV\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/U250\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/U850\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/V250\n",
      "Found 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/V850\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting ERA5 files...\")\n",
    "era5_files = {}\n",
    "for param in ERA5_PARAMS:\n",
    "    param_path = os.path.join(ERA5_PATH, param)\n",
    "    if not os.path.exists(param_path):\n",
    "        print(f\"Directory not found: {param_path}\")\n",
    "        continue\n",
    "    param_files = collect_files(param_path, expected_subdirs=ERA5_PARAMS, data_type=\"ERA5\")\n",
    "    for dt, paths in param_files.items():\n",
    "        if dt not in era5_files:\n",
    "            era5_files[dt] = {}\n",
    "        era5_files[dt][param] = paths[param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:17:15.861766Z",
     "iopub.status.busy": "2025-04-29T03:17:15.861239Z",
     "iopub.status.idle": "2025-04-29T03:17:19.738686Z",
     "shell.execute_reply": "2025-04-29T03:17:19.737683Z",
     "shell.execute_reply.started": "2025-04-29T03:17:15.861736Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Precipitation files...\n",
      "Found 2487 files in /kaggle/input/btl-ai/DATA_SV/Precipitation/Radar\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting Precipitation files...\")\n",
    "precip_files = collect_files(PRECIP_PATH, data_type=\"Radar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:17:19.740073Z",
     "iopub.status.busy": "2025-04-29T03:17:19.739737Z",
     "iopub.status.idle": "2025-04-29T03:17:19.748440Z",
     "shell.execute_reply": "2025-04-29T03:17:19.747498Z",
     "shell.execute_reply.started": "2025-04-29T03:17:19.740046Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số thời điểm đồng bộ: 2337\n"
     ]
    }
   ],
   "source": [
    "# Đồng bộ thời gian\n",
    "common_datetimes = set(hima_files.keys()) & set(era5_files.keys()) & set(precip_files.keys())\n",
    "common_datetimes = sorted(list(common_datetimes))\n",
    "print(f\"Số thời điểm đồng bộ: {len(common_datetimes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T03:17:19.750042Z",
     "iopub.status.busy": "2025-04-29T03:17:19.749520Z",
     "iopub.status.idle": "2025-04-29T03:17:19.802882Z",
     "shell.execute_reply": "2025-04-29T03:17:19.802105Z",
     "shell.execute_reply.started": "2025-04-29T03:17:19.749992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Himawari missing counts:\n",
      "B04B: 1113/2337 (47.63%)\n",
      "B05B: 1175/2337 (50.28%)\n",
      "B06B: 1335/2337 (57.12%)\n",
      "B09B: 1/2337 (0.04%)\n",
      "B10B: 1/2337 (0.04%)\n",
      "B11B: 1/2337 (0.04%)\n",
      "B12B: 1/2337 (0.04%)\n",
      "B14B: 2/2337 (0.09%)\n",
      "B16B: 2/2337 (0.09%)\n",
      "I2B: 2/2337 (0.09%)\n",
      "I4B: 102/2337 (4.36%)\n",
      "IRB: 2/2337 (0.09%)\n",
      "VSB: 1101/2337 (47.11%)\n",
      "WVB: 4/2337 (0.17%)\n",
      "ERA5 missing counts:\n",
      "CAPE: 0/2337 (0.00%)\n",
      "CIN: 0/2337 (0.00%)\n",
      "EWSS: 0/2337 (0.00%)\n",
      "IE: 0/2337 (0.00%)\n",
      "ISOR: 0/2337 (0.00%)\n",
      "KX: 0/2337 (0.00%)\n",
      "PEV: 0/2337 (0.00%)\n",
      "R250: 0/2337 (0.00%)\n",
      "R500: 0/2337 (0.00%)\n",
      "R850: 0/2337 (0.00%)\n",
      "SLHF: 0/2337 (0.00%)\n",
      "SLOR: 0/2337 (0.00%)\n",
      "SSHF: 0/2337 (0.00%)\n",
      "TCLW: 0/2337 (0.00%)\n",
      "TCW: 0/2337 (0.00%)\n",
      "TCWV: 0/2337 (0.00%)\n",
      "U250: 0/2337 (0.00%)\n",
      "U850: 0/2337 (0.00%)\n",
      "V250: 0/2337 (0.00%)\n",
      "V850: 0/2337 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra dữ liệu thiếu\n",
    "hima_missing = {band: 0 for band in HIMA_BANDS}\n",
    "era5_missing = {param: 0 for param in ERA5_PARAMS}\n",
    "for dt in common_datetimes:\n",
    "    for band in HIMA_BANDS:\n",
    "        if not hima_files.get(dt, {}).get(band):\n",
    "            hima_missing[band] += 1\n",
    "    for param in ERA5_PARAMS:\n",
    "        if not era5_files.get(dt, {}).get(param):\n",
    "            era5_missing[param] += 1\n",
    "\n",
    "print(\"Himawari missing counts:\")\n",
    "for band, count in hima_missing.items():\n",
    "    print(f\"{band}: {count}/{len(common_datetimes)} ({count/len(common_datetimes)*100:.2f}%)\")\n",
    "print(\"ERA5 missing counts:\")\n",
    "for param, count in era5_missing.items():\n",
    "    print(f\"{param}: {count}/{len(common_datetimes)} ({count/len(common_datetimes)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7020161,
     "sourceId": 11237152,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
