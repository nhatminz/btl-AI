{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a63adb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-29T18:48:29.623477Z",
     "iopub.status.busy": "2025-04-29T18:48:29.622789Z",
     "iopub.status.idle": "2025-04-29T18:48:33.700654Z",
     "shell.execute_reply": "2025-04-29T18:48:33.699884Z"
    },
    "papermill": {
     "duration": 4.086303,
     "end_time": "2025-04-29T18:48:33.702391",
     "exception": false,
     "start_time": "2025-04-29T18:48:29.616088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GDAL in /usr/local/lib/python3.11/dist-packages (3.6.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install GDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3604bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:48:33.713565Z",
     "iopub.status.busy": "2025-04-29T18:48:33.713333Z",
     "iopub.status.idle": "2025-04-29T18:48:40.947473Z",
     "shell.execute_reply": "2025-04-29T18:48:40.946645Z"
    },
    "papermill": {
     "duration": 7.241325,
     "end_time": "2025-04-29T18:48:40.948951",
     "exception": false,
     "start_time": "2025-04-29T18:48:33.707626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8419afd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:48:40.961635Z",
     "iopub.status.busy": "2025-04-29T18:48:40.961266Z",
     "iopub.status.idle": "2025-04-29T18:48:41.058681Z",
     "shell.execute_reply": "2025-04-29T18:48:41.057871Z"
    },
    "papermill": {
     "duration": 0.104055,
     "end_time": "2025-04-29T18:48:41.059755",
     "exception": false,
     "start_time": "2025-04-29T18:48:40.955700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a59fcd71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:48:41.070771Z",
     "iopub.status.busy": "2025-04-29T18:48:41.070538Z",
     "iopub.status.idle": "2025-04-29T18:48:41.079327Z",
     "shell.execute_reply": "2025-04-29T18:48:41.078781Z"
    },
    "papermill": {
     "duration": 0.015198,
     "end_time": "2025-04-29T18:48:41.080445",
     "exception": false,
     "start_time": "2025-04-29T18:48:41.065247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Đặt seed để tái lập kết quả\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Định nghĩa các hằng số và đường dẫn\n",
    "BASE_PATH = \"/kaggle/input/btl-ai/DATA_SV\"\n",
    "HIMA_PATH = os.path.join(BASE_PATH, \"Hima\")\n",
    "ERA5_PATH = os.path.join(BASE_PATH, \"ERA5\")\n",
    "PRECIP_PATH = os.path.join(BASE_PATH, \"Precipitation/Radar\")\n",
    "OUTPUT_PATH = \"/kaggle/working/output/\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "510dacad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T18:48:41.091568Z",
     "iopub.status.busy": "2025-04-29T18:48:41.091141Z",
     "iopub.status.idle": "2025-04-29T18:48:41.096694Z",
     "shell.execute_reply": "2025-04-29T18:48:41.095931Z"
    },
    "papermill": {
     "duration": 0.012033,
     "end_time": "2025-04-29T18:48:41.097717",
     "exception": true,
     "start_time": "2025-04-29T18:48:41.085684",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (148908960.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_19/148908960.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    SELECTED_ERA5_PARAMS = ['CAPE', 'CIN', 'EWSS', 'IE', 'ISOR', 'KX', 'PEV', 'R250', 'R500', 'R850',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "HIMA_BANDS = ['B04B', 'B05B', 'B06B', 'B09B', 'B10B', 'B11B', 'B12B', 'B14B', 'B16B', 'I2B', 'I4B', 'IRB', 'VSB', 'WVB']  # 14 band\n",
    "ERA5_PARAMS = ['CAPE', 'CIN', 'EWSS', 'IE', 'ISOR', 'KX', 'PEV', 'R250', 'R500', 'R850', 'SLHF', 'SLOR', 'SSHF', 'TCLW', 'TCW', 'TCWV', 'U250', 'U850', 'V250', 'V850']  # 20 tham số\n",
    "HEIGHT, WIDTH = 90, 250\n",
    "\n",
    "# Chọn features để giữ lại\n",
    "SELECTED_HIMA_BANDS = ['B09B', 'B10B', 'B11B', 'B12B', 'B14B', 'B16B', 'I2B', 'IRB', 'WVB', 'I4B']\n",
    "    SELECTED_ERA5_PARAMS = ['CAPE', 'CIN', 'EWSS', 'IE', 'ISOR', 'KX', 'PEV', 'R250', 'R500', 'R850', \n",
    "                           'SLHF', 'SLOR', 'SSHF', 'TCLW', 'TCW', 'TCWV', 'U250', 'U850', 'V250', 'V850']\n",
    "\n",
    "IN_CHANNEL = len(SELECTED_HIMA_BANDS) + len(SELECTED_ERA5_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad84049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.488679Z",
     "iopub.status.busy": "2025-04-29T16:53:41.488391Z",
     "iopub.status.idle": "2025-04-29T16:53:41.502001Z",
     "shell.execute_reply": "2025-04-29T16:53:41.501331Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.488657Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Hàm xử lý dữ liệu\n",
    "# Hàm đọc file GeoTIFF\n",
    "def read_geotiff(file_path):\n",
    "    try:\n",
    "        ds = gdal.Open(file_path)\n",
    "        band = ds.GetRasterBand(1)\n",
    "        data = band.ReadAsArray()\n",
    "        ds = None\n",
    "        if data.shape != (HEIGHT, WIDTH):\n",
    "            print(f\"Invalid shape {data.shape} for file {file_path}, expected ({HEIGHT}, {WIDTH})\")\n",
    "            return None\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed680c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.502864Z",
     "iopub.status.busy": "2025-04-29T16:53:41.502634Z",
     "iopub.status.idle": "2025-04-29T16:53:41.520338Z",
     "shell.execute_reply": "2025-04-29T16:53:41.519660Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.502844Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hàm phân tích thời gian từ tên file\n",
    "def parse_datetime_from_filename(filename, data_type):\n",
    "    try:\n",
    "        if data_type == \"Hima\":\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) < 2:\n",
    "                return None\n",
    "            time_part = parts[1].split('_TB.tif')[0]\n",
    "            time_part = time_part.replace('.Z', '')\n",
    "            dt = datetime.strptime(time_part, '%Y%m%d%H%M')\n",
    "        elif data_type == \"ERA5\":\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) < 2:\n",
    "                return None\n",
    "            time_part = parts[1].replace('.tif', '')\n",
    "            dt = datetime.strptime(time_part, '%Y%m%d%H%M%S')\n",
    "        elif data_type == \"Radar\":\n",
    "            time_part = filename.split('_')[1].replace('.tif', '')\n",
    "            dt = datetime.strptime(time_part, '%Y%m%d%H%M%S')\n",
    "        else:\n",
    "            return None\n",
    "        return dt.replace(minute=0, second=0, microsecond=0)\n",
    "    except Exception as e:\n",
    "        global error_count\n",
    "        if error_count < 5:\n",
    "            print(f\"Error parsing datetime from {filename} (type {data_type}): {e}\")\n",
    "            error_count += 1\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73cdb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.521383Z",
     "iopub.status.busy": "2025-04-29T16:53:41.521167Z",
     "iopub.status.idle": "2025-04-29T16:53:41.535025Z",
     "shell.execute_reply": "2025-04-29T16:53:41.534352Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.521358Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_count = 0\n",
    "\n",
    "# Hàm thu thập file\n",
    "def collect_files(base_path, expected_subdirs=None, data_type=None):\n",
    "    files_dict = {}\n",
    "    file_count = 0\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.tif'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                dt = parse_datetime_from_filename(file, data_type)\n",
    "                if dt is None:\n",
    "                    continue\n",
    "                file_count += 1\n",
    "                if expected_subdirs:\n",
    "                    subdir = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(file_path)))))\n",
    "                    if dt not in files_dict:\n",
    "                        files_dict[dt] = {}\n",
    "                    files_dict[dt][subdir] = file_path\n",
    "                else:\n",
    "                    files_dict[dt] = file_path\n",
    "    print(f\"Found {file_count} files in {base_path}\")\n",
    "    return files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03962d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.535962Z",
     "iopub.status.busy": "2025-04-29T16:53:41.535722Z",
     "iopub.status.idle": "2025-04-29T16:53:41.552388Z",
     "shell.execute_reply": "2025-04-29T16:53:41.551702Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.535924Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hàm xử lý dữ liệu thiếu và chuẩn hóa\n",
    "def preprocess_data(data, data_type):\n",
    "    if data is None:\n",
    "        return None\n",
    "    # Xử lý giá trị không hợp lệ\n",
    "    data = np.where(np.isinf(data) | np.isnan(data) | (data == -9999), 0, data)\n",
    "    if data_type == \"Radar\":\n",
    "        # Log transformation cho radar\n",
    "        data = np.log1p(np.maximum(data, 0))  # log(1 + x)\n",
    "    else:\n",
    "        # Min-max scaling cho Himawari và ERA5\n",
    "        data_min, data_max = np.min(data), np.max(data)\n",
    "        if data_max > data_min:\n",
    "            data = (data - data_min) / (data_max - data_min)\n",
    "        else:\n",
    "            data = np.zeros_like(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3e6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.553466Z",
     "iopub.status.busy": "2025-04-29T16:53:41.553242Z",
     "iopub.status.idle": "2025-04-29T16:53:41.566238Z",
     "shell.execute_reply": "2025-04-29T16:53:41.565546Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.553443Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FocalLoss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=0.25):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "    def forward(self, y_pred, y_true):\n",
    "        mse_loss = nn.functional.mse_loss(y_pred, y_true, reduction='none')\n",
    "        pt = torch.exp(-mse_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * mse_loss\n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161b4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.567295Z",
     "iopub.status.busy": "2025-04-29T16:53:41.567086Z",
     "iopub.status.idle": "2025-04-29T16:53:41.581347Z",
     "shell.execute_reply": "2025-04-29T16:53:41.580755Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.567274Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "def create_time_sequences(hima_files, era5_files, precip_files, common_datetimes, seq_len=5, max_gap_hours=3, batch_size=500):\n",
    "    # Tính giá trị trung bình để điền dữ liệu thiếu\n",
    "    hima_sums = {band: np.zeros((HEIGHT, WIDTH), dtype=np.float64) for band in SELECTED_HIMA_BANDS}\n",
    "    era5_sums = {param: np.zeros((HEIGHT, WIDTH), dtype=np.float64) for param in SELECTED_ERA5_PARAMS}\n",
    "    radar_sum = np.zeros((HEIGHT, WIDTH), dtype=np.float64)\n",
    "    hima_counts = {band: 0 for band in SELECTED_HIMA_BANDS}\n",
    "    era5_counts = {param: 0 for param in SELECTED_ERA5_PARAMS}\n",
    "    radar_count = 0\n",
    "    \n",
    "    for dt in common_datetimes:\n",
    "        for band in SELECTED_HIMA_BANDS:\n",
    "            file_path = hima_files.get(dt, {}).get(band)\n",
    "            if file_path:\n",
    "                data = read_geotiff(file_path)\n",
    "                if data is not None:\n",
    "                    hima_sums[band] += data\n",
    "                    hima_counts[band] += 1\n",
    "        for param in SELECTED_ERA5_PARAMS:\n",
    "            file_path = era5_files.get(dt, {}).get(param)\n",
    "            if file_path:\n",
    "                data = read_geotiff(file_path)\n",
    "                if data is not None:\n",
    "                    era5_sums[param] += data\n",
    "                    era5_counts[param] += 1\n",
    "        radar_file = precip_files.get(dt)\n",
    "        if radar_file:\n",
    "            data = read_geotiff(radar_file)\n",
    "            if data is not None:\n",
    "                radar_sum += data\n",
    "                radar_count += 1\n",
    "    \n",
    "    hima_means = {band: (sums / count if count > 0 else np.zeros((HEIGHT, WIDTH))) \n",
    "                  for band, sums, count in zip(SELECTED_HIMA_BANDS, hima_sums.values(), hima_counts.values())}\n",
    "    era5_means = {param: (sums / count if count > 0 else np.zeros((HEIGHT, WIDTH))) \n",
    "                  for param, sums, count in zip(SELECTED_ERA5_PARAMS, era5_sums.values(), era5_counts.values())}\n",
    "    radar_mean = radar_sum / radar_count if radar_count > 0 else np.zeros((HEIGHT, WIDTH))\n",
    "    \n",
    "    # Tạo thư mục lưu trữ\n",
    "    if not os.path.exists('sequences'):\n",
    "        os.makedirs('sequences')\n",
    "    \n",
    "    # Xử lý theo batch\n",
    "    total_samples = 0\n",
    "    for batch_start in range(seq_len-1, len(common_datetimes), batch_size):\n",
    "        batch_end = min(batch_start + batch_size, len(common_datetimes))\n",
    "        X_batch, y_batch = [], []\n",
    "        discontinuity_count = 0\n",
    "        \n",
    "        for i in range(batch_start, batch_end):\n",
    "            dt = common_datetimes[i]\n",
    "            sequence = []\n",
    "            valid_sequence = True\n",
    "            \n",
    "            for j in range(seq_len-1, -1, -1):\n",
    "                target_dt = dt - timedelta(hours=j)\n",
    "                dt_diffs = [(abs((target_dt - dt_i).total_seconds()), dt_i) for dt_i in common_datetimes]\n",
    "                dt_diffs.sort()\n",
    "                closest_dt, closest_dt_diff = dt_diffs[0][1], dt_diffs[0][0] / 3600\n",
    "                \n",
    "                if closest_dt_diff > max_gap_hours:\n",
    "                    valid_sequence = False\n",
    "                    discontinuity_count += 1\n",
    "                    break\n",
    "                \n",
    "                hima_data = []\n",
    "                for band in SELECTED_HIMA_BANDS:\n",
    "                    file_path = hima_files.get(closest_dt, {}).get(band)\n",
    "                    if not file_path:\n",
    "                        data = hima_means[band]\n",
    "                    else:\n",
    "                        data = read_geotiff(file_path)\n",
    "                        data = preprocess_data(data, \"Hima\")\n",
    "                        if data is None:\n",
    "                            data = hima_means[band]\n",
    "                    hima_data.append(data)\n",
    "                hima_data = np.stack(hima_data, axis=-1)\n",
    "                \n",
    "                era5_data = []\n",
    "                for param in SELECTED_ERA5_PARAMS:\n",
    "                    file_path = era5_files.get(closest_dt, {}).get(param)\n",
    "                    if not file_path:\n",
    "                        data = era5_means[param]\n",
    "                    else:\n",
    "                        data = read_geotiff(file_path)\n",
    "                        data = preprocess_data(data, \"ERA5\")\n",
    "                        if data is None:\n",
    "                            data = era5_means[param]\n",
    "                    era5_data.append(data)\n",
    "                era5_data = np.stack(era5_data, axis=-1)\n",
    "                \n",
    "                combined = np.concatenate([hima_data, era5_data], axis=-1)\n",
    "                sequence.append(combined)\n",
    "            \n",
    "            if not valid_sequence:\n",
    "                continue\n",
    "            \n",
    "            radar_file = precip_files.get(dt)\n",
    "            if not radar_file:\n",
    "                radar_data = radar_mean\n",
    "            else:\n",
    "                radar_data = read_geotiff(radar_file)\n",
    "                radar_data = preprocess_data(radar_data, \"Radar\")\n",
    "                if radar_data is None:\n",
    "                    radar_data = radar_mean\n",
    "            \n",
    "            sequence = np.stack(sequence, axis=0)\n",
    "            X_batch.append(sequence)\n",
    "            y_batch.append(radar_data)\n",
    "        \n",
    "        # Lưu batch xuống đĩa\n",
    "        X_batch = np.array(X_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "        X_batch = X_batch.transpose(0, 1, 4, 2, 3)  # (samples, seq_len, channels, height, width)\n",
    "        batch_idx = batch_start // batch_size\n",
    "        np.save(f'sequences/X_batch_{batch_idx}.npy', X_batch)\n",
    "        np.save(f'sequences/y_batch_{batch_idx}.npy', y_batch)\n",
    "        total_samples += X_batch.shape[0]\n",
    "        print(f\"Saved batch {batch_idx}, samples: {X_batch.shape[0]}\")\n",
    "    \n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    return total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18de7c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.582221Z",
     "iopub.status.busy": "2025-04-29T16:53:41.582027Z",
     "iopub.status.idle": "2025-04-29T16:53:41.602040Z",
     "shell.execute_reply": "2025-04-29T16:53:41.601352Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.582199Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa lớp ConvLSTMCell tùy chỉnh\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels + out_channels, 4 * out_channels, kernel_size,\n",
    "            padding=padding, bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        # x: (batch, in_channels, height, width)\n",
    "        # h_prev, c_prev: (batch, out_channels, height, width)\n",
    "        combined = torch.cat([x, h_prev], dim=1)  # (batch, in_channels + out_channels, height, width)\n",
    "        conv_out = self.conv(combined)  # (batch, 4 * out_channels, height, width)\n",
    "        i, f, o, g = torch.chunk(conv_out, 4, dim=1)  # Mỗi cái: (batch, out_channels, height, width)\n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        o = torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "        c_next = f * c_prev + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa4c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.603379Z",
     "iopub.status.busy": "2025-04-29T16:53:41.603137Z",
     "iopub.status.idle": "2025-04-29T16:53:41.616230Z",
     "shell.execute_reply": "2025-04-29T16:53:41.615684Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.603358Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa lớp ConvLSTM2d\n",
    "class ConvLSTM2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super(ConvLSTM2d, self).__init__()\n",
    "        self.cell = ConvLSTMCell(in_channels, out_channels, kernel_size, padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Kiểm tra số chiều của đầu vào\n",
    "        if len(x.size()) == 5:\n",
    "            # x: (batch, seq_len, channels, height, width)\n",
    "            batch, seq_len, channels, height, width = x.size()\n",
    "            is_sequence = True\n",
    "        elif len(x.size()) == 4:\n",
    "            # x: (batch, channels, height, width)\n",
    "            batch, channels, height, width = x.size()\n",
    "            seq_len = 1\n",
    "            x = x.unsqueeze(1)  # Thêm chiều seq_len: (batch, 1, channels, height, width)\n",
    "            is_sequence = False\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 4 or 5 dimensions, got {len(x.size())}\")\n",
    "\n",
    "        out_channels = self.cell.out_channels\n",
    "        h = torch.zeros(batch, out_channels, height, width, device=x.device)\n",
    "        c = torch.zeros(batch, out_channels, height, width, device=x.device)\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :, :, :]  # (batch, channels, height, width)\n",
    "            h, c = self.cell(x_t, h, c)\n",
    "            outputs.append(h)\n",
    "        output = outputs[-1] if is_sequence else h\n",
    "        return output, (h, c)  # Trả về output cuối và trạng thái"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3dec8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.619233Z",
     "iopub.status.busy": "2025-04-29T16:53:41.619044Z",
     "iopub.status.idle": "2025-04-29T16:53:41.633055Z",
     "shell.execute_reply": "2025-04-29T16:53:41.632459Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.619220Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_loader, val_loader, output_path, epochs=30, patience=7, lr=0.0001):\n",
    "    criterion = FocalLoss(gamma=2.0, alpha=0.25)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        total_train_samples = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "            total_train_samples += X_batch.size(0)\n",
    "            if batch_idx % 10 == 0:  # In thông tin mỗi 10 batch\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx}, Batch size: {X_batch.size(0)}, Loss: {loss.item():.4f}\")\n",
    "        train_loss /= total_train_samples\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        total_val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                output = model(X_batch)\n",
    "                loss = criterion(output, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "                total_val_samples += X_batch.size(0)\n",
    "            val_loss /= total_val_samples\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            # Lưu mô hình tốt nhất\n",
    "            torch.save(best_model_state, os.path.join(output_path, \"best_convlstm_model.pth\"))\n",
    "            print(f\"Saved best model at epoch {epoch+1} with Val Loss: {best_loss:.4f}\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefbc456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.633892Z",
     "iopub.status.busy": "2025-04-29T16:53:41.633626Z",
     "iopub.status.idle": "2025-04-29T16:53:41.650507Z",
     "shell.execute_reply": "2025-04-29T16:53:41.649765Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.633873Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Định nghĩa mô hình ConvLSTM\n",
    "class ConvLSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "        self.convlstm1 = ConvLSTM2d(in_channels=IN_CHANNEL, out_channels=64, kernel_size=(5, 5), padding=(2, 2))\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.convlstm2 = ConvLSTM2d(in_channels=64, out_channels=32, kernel_size=(5, 5), padding=(2, 2))\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.conv = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=(3, 3), padding=(1, 1))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len=5, channels=34, height=90, width=250)\n",
    "        #print(f\"Input shape: {x.shape}\")\n",
    "        x, _ = self.convlstm1(x)  # (batch, 64, height, width)\n",
    "        x = self.bn1(x)\n",
    "        #print(f\"After convlstm1: {x.shape}\")\n",
    "        x, _ = self.convlstm2(x)  # (batch, 32, height, width)\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv(x)  # (batch, 1, height, width)\n",
    "        x = self.relu(x)\n",
    "        return x.squeeze(1)  # (batch, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3cb83",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, total_samples, batch_size=500):\n",
    "        self.total_samples = total_samples\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = (total_samples + batch_size - 1) // batch_size\n",
    "        self.batch_sizes = []\n",
    "        for batch_idx in range(self.num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = min(batch_start + batch_size, total_samples)\n",
    "            self.batch_sizes.append(batch_end - batch_start)\n",
    "            print(f\"Batch {batch_idx}: {self.batch_sizes[-1]} sequences\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.total_samples:\n",
    "            raise IndexError(f\"Index {idx} out of range (total samples: {self.total_samples})\")\n",
    "        batch_idx = idx // self.batch_size\n",
    "        within_batch_idx = idx % self.batch_size\n",
    "        if within_batch_idx >= self.batch_sizes[batch_idx]:\n",
    "            raise IndexError(f\"Within batch index {within_batch_idx} exceeds batch size {self.batch_sizes[batch_idx]} for batch {batch_idx}\")\n",
    "        X_batch = np.load(f'sequences/X_batch_{batch_idx}.npy')\n",
    "        y_batch = np.load(f'sequences/y_batch_{batch_idx}.npy')\n",
    "        X_sample = X_batch[within_batch_idx]\n",
    "        y_sample = y_batch[within_batch_idx]\n",
    "        return torch.tensor(X_sample, dtype=torch.float32), torch.tensor(y_sample, dtype=torch.float32)\n",
    "\n",
    "def create_dataloaders(total_samples, batch_size=2, train_ratio=0.7, val_ratio=0.15):\n",
    "    dataset = SequenceDataset(total_samples, batch_size=500)\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    val_size = int(val_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395cbb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.651404Z",
     "iopub.status.busy": "2025-04-29T16:53:41.651194Z",
     "iopub.status.idle": "2025-04-29T16:53:41.667471Z",
     "shell.execute_reply": "2025-04-29T16:53:41.666973Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.651390Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hàm tính chỉ số đánh giá\n",
    "def evaluate_model(y_true, y_pred, threshold=0.0):\n",
    "    y_true = y_true.reshape(-1)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    corr = np.corrcoef(y_true, y_pred)[0, 1] if np.std(y_true) > 0 and np.std(y_pred) > 0 else 0\n",
    "\n",
    "    y_true_bin = (y_true > threshold).astype(int)\n",
    "    y_pred_bin = (y_pred > threshold).astype(int)\n",
    "    hits = np.sum((y_true_bin == 1) & (y_pred_bin == 1))\n",
    "    misses = np.sum((y_true_bin == 1) & (y_pred_bin == 0))\n",
    "    false_alarms = np.sum((y_true_bin == 0) & (y_pred_bin == 1))\n",
    "    true_negatives = np.sum((y_true_bin == 0) & (y_pred_bin == 0))\n",
    "    total = hits + misses + false_alarms + true_negatives\n",
    "\n",
    "    accuracy = (hits + true_negatives) / total if total > 0 else 0\n",
    "    csi = hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0\n",
    "    far = false_alarms / (hits + false_alarms) if (hits + false_alarms) > 0 else 0\n",
    "    hss = (2 * (hits * true_negatives - misses * false_alarms)) / \\\n",
    "          ((hits + misses) * (misses + true_negatives) + (hits + false_alarms) * (false_alarms + true_negatives)) \\\n",
    "          if ((hits + misses) * (misses + true_negatives) + (hits + false_alarms) * (false_alarms + true_negatives)) > 0 else 0\n",
    "    ets = ((hits - ((hits + misses) * (hits + false_alarms) / total)) / \\\n",
    "           (hits + misses + false_alarms - ((hits + misses) * (hits + false_alarms) / total))) \\\n",
    "          if (hits + misses + false_alarms - ((hits + misses) * (hits + false_alarms) / total)) > 0 else 0\n",
    "\n",
    "    return {'rmse': rmse, 'corr': corr, 'accuracy': accuracy, 'csi': csi, 'far': far, 'hss': hss, 'ets': ets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc53d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.668309Z",
     "iopub.status.busy": "2025-04-29T16:53:41.668106Z",
     "iopub.status.idle": "2025-04-29T16:53:41.686803Z",
     "shell.execute_reply": "2025-04-29T16:53:41.686299Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.668288Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hàm vẽ scatter plot\n",
    "def plot_scatter(y_true, y_pred, output_path):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_true.flatten(), y_pred.flatten(), alpha=0.5)\n",
    "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
    "    plt.xlabel('Ground Truth (mm/h)')\n",
    "    plt.ylabel('Predicted (mm/h)')\n",
    "    plt.title('Scatter Plot: Predicted vs Ground Truth')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbacca51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.687731Z",
     "iopub.status.busy": "2025-04-29T16:53:41.687420Z",
     "iopub.status.idle": "2025-04-29T16:53:41.707980Z",
     "shell.execute_reply": "2025-04-29T16:53:41.707379Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.687711Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hàm hiển thị bản đồ\n",
    "def plot_rainfall_map(y_true, y_pred, output_path):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    ax1.set_title('Ground Truth')\n",
    "    ax2.set_title('Prediction')\n",
    "    for ax, data in [(ax1, y_true), (ax2, y_pred)]:\n",
    "        ax.coastlines()\n",
    "        ax.add_feature(cfeature.BORDERS)\n",
    "        im = ax.imshow(data, cmap='Blues', origin='upper', transform=ccrs.PlateCarree())\n",
    "        plt.colorbar(im, ax=ax, label='Rainfall (mm/h)')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcabdf3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.709278Z",
     "iopub.status.busy": "2025-04-29T16:53:41.708698Z",
     "iopub.status.idle": "2025-04-29T16:53:41.721773Z",
     "shell.execute_reply": "2025-04-29T16:53:41.721294Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.709260Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hàm lưu GeoTIFF\n",
    "def save_geotiff(data, output_path, reference_file):\n",
    "    ds = gdal.Open(reference_file)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    out_ds = driver.Create(output_path, WIDTH, HEIGHT, 1, gdal.GDT_Float32)\n",
    "    out_ds.SetGeoTransform(ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(ds.GetProjection())\n",
    "    out_band = out_ds.GetRasterBand(1)\n",
    "    out_band.WriteArray(data)\n",
    "    out_band.FlushCache()\n",
    "    out_ds = None\n",
    "    ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7374a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:53:41.722700Z",
     "iopub.status.busy": "2025-04-29T16:53:41.722496Z",
     "iopub.status.idle": "2025-04-29T16:54:06.990024Z",
     "shell.execute_reply": "2025-04-29T16:54:06.989358Z",
     "shell.execute_reply.started": "2025-04-29T16:53:41.722686Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bắt đầu chương trình\n",
    "print(\"Collecting Himawari files...\")\n",
    "hima_files = {}\n",
    "for band in SELECTED_HIMA_BANDS:\n",
    "    band_path = os.path.join(HIMA_PATH, band)\n",
    "    if not os.path.exists(band_path):\n",
    "        print(f\"Directory not found: {band_path}\")\n",
    "        continue\n",
    "    band_files = collect_files(band_path, expected_subdirs=SELECTED_HIMA_BANDS, data_type=\"Hima\")\n",
    "    for dt, paths in band_files.items():\n",
    "        if dt not in hima_files:\n",
    "            hima_files[dt] = {}\n",
    "        hima_files[dt][band] = paths[band]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c99bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:54:06.990979Z",
     "iopub.status.busy": "2025-04-29T16:54:06.990722Z",
     "iopub.status.idle": "2025-04-29T16:54:24.423711Z",
     "shell.execute_reply": "2025-04-29T16:54:24.423003Z",
     "shell.execute_reply.started": "2025-04-29T16:54:06.990961Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Collecting ERA5 files...\")\n",
    "era5_files = {}\n",
    "for param in SELECTED_ERA5_PARAMS:\n",
    "    param_path = os.path.join(ERA5_PATH, param)\n",
    "    if not os.path.exists(param_path):\n",
    "        print(f\"Directory not found: {param_path}\")\n",
    "        continue\n",
    "    param_files = collect_files(param_path, expected_subdirs=SELECTED_ERA5_PARAMS, data_type=\"ERA5\")\n",
    "    for dt, paths in param_files.items():\n",
    "        if dt not in era5_files:\n",
    "            era5_files[dt] = {}\n",
    "        era5_files[dt][param] = paths[param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c8464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:54:24.425048Z",
     "iopub.status.busy": "2025-04-29T16:54:24.424769Z",
     "iopub.status.idle": "2025-04-29T16:54:26.584338Z",
     "shell.execute_reply": "2025-04-29T16:54:26.583695Z",
     "shell.execute_reply.started": "2025-04-29T16:54:24.425021Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Collecting Precipitation files...\")\n",
    "precip_files = collect_files(PRECIP_PATH, data_type=\"Radar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca6c1ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:54:26.585244Z",
     "iopub.status.busy": "2025-04-29T16:54:26.585030Z",
     "iopub.status.idle": "2025-04-29T16:54:26.591607Z",
     "shell.execute_reply": "2025-04-29T16:54:26.590887Z",
     "shell.execute_reply.started": "2025-04-29T16:54:26.585228Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Đồng bộ thời gian\n",
    "common_datetimes = set(hima_files.keys()) & set(era5_files.keys()) & set(precip_files.keys())\n",
    "common_datetimes = sorted(list(common_datetimes))\n",
    "print(f\"Số thời điểm đồng bộ: {len(common_datetimes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910c88f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:54:26.592779Z",
     "iopub.status.busy": "2025-04-29T16:54:26.592455Z",
     "iopub.status.idle": "2025-04-29T16:54:26.607237Z",
     "shell.execute_reply": "2025-04-29T16:54:26.606733Z",
     "shell.execute_reply.started": "2025-04-29T16:54:26.592741Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Kiểm tra dữ liệu thiếu\n",
    "# hima_missing = {band: 0 for band in SELECTED_HIMA_BANDS}\n",
    "# era5_missing = {param: 0 for param in ERA5_PARAMS}\n",
    "# for dt in common_datetimes:\n",
    "#     for band in SELECTED_HIMA_BANDS:\n",
    "#         if not hima_files.get(dt, {}).get(band):\n",
    "#             hima_missing[band] += 1\n",
    "#     for param in ERA5_PARAMS:\n",
    "#         if not era5_files.get(dt, {}).get(param):\n",
    "#             era5_missing[param] += 1\n",
    "# print(\"Himawari missing counts:\")\n",
    "# for band, count in hima_missing.items():\n",
    "#     print(f\"{band}: {count}/{len(common_datetimes)} ({count/len(common_datetimes)*100:.2f}%)\")\n",
    "# print(\"ERA5 missing counts:\")\n",
    "# for param, count in era5_missing.items():\n",
    "#     print(f\"{param}: {count}/{len(common_datetimes)} ({count/len(common_datetimes)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784b7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:54:26.608106Z",
     "iopub.status.busy": "2025-04-29T16:54:26.607864Z",
     "iopub.status.idle": "2025-04-29T16:54:26.621825Z",
     "shell.execute_reply": "2025-04-29T16:54:26.621179Z",
     "shell.execute_reply.started": "2025-04-29T16:54:26.608087Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# radar_missing = 0\n",
    "# for dt in common_datetimes:\n",
    "#     if not precip_files.get(dt):\n",
    "#         ra0dar_missing += 1\n",
    "# print(f\"Radar missing counts: {radar_missing}/{len(common_datetimes)} ({radar_missing/len(common_datetimes)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892477df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T16:54:26.622616Z",
     "iopub.status.busy": "2025-04-29T16:54:26.622431Z",
     "iopub.status.idle": "2025-04-29T17:05:14.093970Z",
     "shell.execute_reply": "2025-04-29T17:05:14.088126Z",
     "shell.execute_reply.started": "2025-04-29T16:54:26.622601Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tạo chuỗi thời gian\n",
    "print(\"Creating time sequences...\")\n",
    "total_samples = create_time_sequences(hima_files, era5_files, precip_files, common_datetimes, seq_len=5, max_gap_hours=3, batch_size=500)\n",
    "print(f\"Total samples: {total_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec3969",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-29T17:05:35.455Z",
     "iopub.execute_input": "2025-04-29T17:05:14.094964Z",
     "iopub.status.busy": "2025-04-29T17:05:14.094750Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chia dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041e329",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-29T17:05:35.455Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tạo DataLoader\n",
    "train_loader, val_loader, test_loader = create_dataloaders(total_samples, batch_size=2, train_ratio=0.7, val_ratio=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9addc6",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-29T17:05:35.455Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Khởi tạo và huấn luyện mô hình\n",
    "model = ConvLSTMModel().to(device)\n",
    "model = train_model(model, train_loader, val_loader, OUTPUT_PATH, epochs=30, patience=7, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355f578",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-29T17:05:35.455Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Đánh giá trên tập kiểm thử\n",
    "model.eval()\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        output = model(X_batch)\n",
    "        y_pred.append(output.cpu().numpy())\n",
    "y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "# Đánh giá\n",
    "metrics = evaluate_model(y_test.numpy(), y_pred, threshold=1.0)\n",
    "print(\"Evaluation Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e1e0f",
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-29T17:05:35.455Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vẽ scatter plot\n",
    "plot_scatter(y_test.numpy(), y_pred, os.path.join(OUTPUT_PATH, 'scatter_plot.png'))\n",
    "\n",
    "# Vẽ bản đồ cho mẫu đầu tiên\n",
    "plot_rainfall_map(y_test[0].numpy(), y_pred[0], os.path.join(OUTPUT_PATH, 'rainfall_map.png'))\n",
    "\n",
    "# Lưu bản đồ dự đoán dưới dạng GeoTIFF\n",
    "save_geotiff(y_pred[0], os.path.join(OUTPUT_PATH, 'predicted_rainfall.tif'),\n",
    "             precip_files[common_datetimes[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342657e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7020161,
     "sourceId": 11237152,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.382909,
   "end_time": "2025-04-29T18:48:43.455315",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-29T18:48:25.072406",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
