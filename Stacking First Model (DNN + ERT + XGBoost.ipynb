{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11651856,"sourceType":"datasetVersion","datasetId":7310237}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load dữ liệu (giả sử bạn đã có sẵn df)\ndf = pd.read_csv(\"/kaggle/input/data-full-features-ai/weather_data_nghean (1).csv\")\n\n# Kiểm tra thông tin tổng quát\nprint(df.info())\nprint(df.describe())\n\ndf.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-05T02:27:33.184031Z","iopub.execute_input":"2025-05-05T02:27:33.184215Z","iopub.status.idle":"2025-05-05T02:27:40.212191Z","shell.execute_reply.started":"2025-05-05T02:27:33.184199Z","shell.execute_reply":"2025-05-05T02:27:40.211561Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 388493 entries, 0 to 388492\nData columns (total 38 columns):\n #   Column    Non-Null Count   Dtype  \n---  ------    --------------   -----  \n 0   x         388493 non-null  float64\n 1   y         388493 non-null  float64\n 2   B04B      388493 non-null  float64\n 3   B05B      388493 non-null  float64\n 4   B06B      388493 non-null  float64\n 5   B09B      388493 non-null  float64\n 6   B10B      388493 non-null  float64\n 7   B11B      388493 non-null  float64\n 8   B12B      388493 non-null  float64\n 9   B14B      388493 non-null  float64\n 10  B16B      388493 non-null  float64\n 11  I2B       388493 non-null  float64\n 12  I4B       388493 non-null  float64\n 13  IRB       388493 non-null  float64\n 14  VSB       388493 non-null  float64\n 15  WVB       388493 non-null  float64\n 16  CAPE      388493 non-null  float64\n 17  CIN       388493 non-null  float64\n 18  EWSS      388493 non-null  float64\n 19  IE        388493 non-null  float64\n 20  ISOR      388493 non-null  float64\n 21  KX        388493 non-null  float64\n 22  PEV       388493 non-null  float64\n 23  R250      388493 non-null  float64\n 24  R500      388493 non-null  float64\n 25  R850      388493 non-null  float64\n 26  SLHF      388493 non-null  float64\n 27  SLOR      388493 non-null  float64\n 28  SSHF      388493 non-null  float64\n 29  TCLW      388493 non-null  float64\n 30  TCW       388493 non-null  float64\n 31  TCWV      388493 non-null  float64\n 32  U250      388493 non-null  float64\n 33  U850      388493 non-null  float64\n 34  V250      388493 non-null  float64\n 35  V850      388493 non-null  float64\n 36  Radar     388493 non-null  float64\n 37  datetime  388493 non-null  object \ndtypes: float64(37), object(1)\nmemory usage: 112.6+ MB\nNone\n                   x              y           B04B           B05B  \\\ncount  388493.000000  388493.000000  388493.000000  388493.000000   \nmean      104.949809      19.234241       0.294234       0.174581   \nstd         0.437629       0.310876       0.199693       0.123118   \nmin       103.900000      18.560000       0.000391       0.000326   \n25%       104.620000      19.000000       0.141541       0.080861   \n50%       104.980000      19.240000       0.251780       0.155233   \n75%       105.300000      19.440000       0.437042       0.253082   \nmax       105.780000      19.960000       0.923014       0.612529   \n\n                B06B           B09B           B10B           B11B  \\\ncount  388493.000000  388493.000000  388493.000000  388493.000000   \nmean        0.129021     243.419956     250.408793     271.419048   \nstd         0.095252      10.202720      12.674594      21.098207   \nmin         0.000326     198.584960     169.366670     169.545000   \n25%         0.041728     238.151980     244.618580     259.743530   \n50%         0.118703     245.584880     254.291060     278.781040   \n75%         0.209381     250.669970     259.575560     287.011350   \nmax         0.433777     262.196000     268.004850     303.228880   \n\n                B12B           B14B  ...           SLOR          SSHF  \\\ncount  388493.000000  388493.000000  ...  388493.000000  3.884930e+05   \nmean      255.579941     272.033474  ...       0.028054 -9.036349e+04   \nstd        13.180805      22.568102  ...       0.014501  1.854509e+05   \nmin       176.324800     169.685610  ...       0.000701 -1.469406e+06   \n25%       248.202160     258.477700  ...       0.016802 -1.607370e+05   \n50%       260.255700     280.006770  ...       0.028084 -2.627300e+04   \n75%       265.263920     289.189640  ...       0.040154  2.112800e+04   \nmax       275.978500     306.162450  ...       0.058033  3.990850e+05   \n\n                TCLW            TCW           TCWV           U250  \\\ncount  388493.000000  388493.000000  388493.000000  388493.000000   \nmean        0.219809      43.269879      42.926766      11.939170   \nstd         0.232675       8.946554       8.712348      15.162809   \nmin         0.000000      14.542634      14.542566     -22.836090   \n25%         0.059570      36.939102      36.731980      -3.439392   \n50%         0.128784      42.879913      42.662720      15.895691   \n75%         0.311035      49.382996      48.897170      24.974121   \nmax         1.454712      75.416110      71.073074      42.879456   \n\n                U850           V250           V850          Radar  \ncount  388493.000000  388493.000000  388493.000000  388493.000000  \nmean       -1.525150       4.590938      -0.703348       0.204880  \nstd         5.760290       7.601398       5.227427       1.360052  \nmin       -24.732285     -13.504059     -22.774704       0.000000  \n25%        -4.977386      -0.895676      -3.536209       0.000000  \n50%        -1.275269       3.602570       0.969681       0.000000  \n75%         2.725372       9.770599       3.042831       0.000000  \nmax        12.849945      27.846588       9.968582      82.570000  \n\n[8 rows x 37 columns]\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"        x      y      B04B      B05B      B06B       B09B       B10B  \\\n0  104.90  19.96  0.498362  0.352224  0.236776  255.42627  260.79110   \n1  104.94  19.96  0.498362  0.352224  0.236776  255.42627  260.79110   \n2  104.98  19.96  0.572723  0.384196  0.249166  255.30000  260.90370   \n3  104.86  19.92  0.532949  0.360718  0.238078  255.81377  260.79684   \n4  104.90  19.92  0.532949  0.360718  0.238078  255.81377  260.79684   \n\n        B11B      B12B       B14B  ...      SSHF      TCLW        TCW  \\\n0  279.25586  259.7476  281.53525  ... -137404.0  0.601746  35.615920   \n1  279.25586  259.7476  281.53525  ... -137404.0  0.601746  35.615920   \n2  280.62646  260.5460  283.24900  ... -137404.0  0.601746  35.615920   \n3  278.82367  259.3540  280.84116  ... -272124.0  0.550171  32.744827   \n4  278.82367  259.3540  280.84116  ... -137404.0  0.601746  35.615920   \n\n        TCWV       U250      U850      V250      V850  Radar  \\\n0  35.005510  25.895142 -4.906418  6.482254  5.172928    0.0   \n1  35.005510  25.895142 -4.906418  6.482254  5.172928    0.0   \n2  35.005510  25.895142 -4.906418  6.482254  5.172928    0.0   \n3  32.179337  26.195923 -4.334152  6.599442  3.686600    0.0   \n4  35.005510  25.895142 -4.906418  6.482254  5.172928    0.0   \n\n              datetime  \n0  2019-04-01 08:00:00  \n1  2019-04-01 08:00:00  \n2  2019-04-01 08:00:00  \n3  2019-04-01 08:00:00  \n4  2019-04-01 08:00:00  \n\n[5 rows x 38 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>B04B</th>\n      <th>B05B</th>\n      <th>B06B</th>\n      <th>B09B</th>\n      <th>B10B</th>\n      <th>B11B</th>\n      <th>B12B</th>\n      <th>B14B</th>\n      <th>...</th>\n      <th>SSHF</th>\n      <th>TCLW</th>\n      <th>TCW</th>\n      <th>TCWV</th>\n      <th>U250</th>\n      <th>U850</th>\n      <th>V250</th>\n      <th>V850</th>\n      <th>Radar</th>\n      <th>datetime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>104.90</td>\n      <td>19.96</td>\n      <td>0.498362</td>\n      <td>0.352224</td>\n      <td>0.236776</td>\n      <td>255.42627</td>\n      <td>260.79110</td>\n      <td>279.25586</td>\n      <td>259.7476</td>\n      <td>281.53525</td>\n      <td>...</td>\n      <td>-137404.0</td>\n      <td>0.601746</td>\n      <td>35.615920</td>\n      <td>35.005510</td>\n      <td>25.895142</td>\n      <td>-4.906418</td>\n      <td>6.482254</td>\n      <td>5.172928</td>\n      <td>0.0</td>\n      <td>2019-04-01 08:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>104.94</td>\n      <td>19.96</td>\n      <td>0.498362</td>\n      <td>0.352224</td>\n      <td>0.236776</td>\n      <td>255.42627</td>\n      <td>260.79110</td>\n      <td>279.25586</td>\n      <td>259.7476</td>\n      <td>281.53525</td>\n      <td>...</td>\n      <td>-137404.0</td>\n      <td>0.601746</td>\n      <td>35.615920</td>\n      <td>35.005510</td>\n      <td>25.895142</td>\n      <td>-4.906418</td>\n      <td>6.482254</td>\n      <td>5.172928</td>\n      <td>0.0</td>\n      <td>2019-04-01 08:00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>104.98</td>\n      <td>19.96</td>\n      <td>0.572723</td>\n      <td>0.384196</td>\n      <td>0.249166</td>\n      <td>255.30000</td>\n      <td>260.90370</td>\n      <td>280.62646</td>\n      <td>260.5460</td>\n      <td>283.24900</td>\n      <td>...</td>\n      <td>-137404.0</td>\n      <td>0.601746</td>\n      <td>35.615920</td>\n      <td>35.005510</td>\n      <td>25.895142</td>\n      <td>-4.906418</td>\n      <td>6.482254</td>\n      <td>5.172928</td>\n      <td>0.0</td>\n      <td>2019-04-01 08:00:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104.86</td>\n      <td>19.92</td>\n      <td>0.532949</td>\n      <td>0.360718</td>\n      <td>0.238078</td>\n      <td>255.81377</td>\n      <td>260.79684</td>\n      <td>278.82367</td>\n      <td>259.3540</td>\n      <td>280.84116</td>\n      <td>...</td>\n      <td>-272124.0</td>\n      <td>0.550171</td>\n      <td>32.744827</td>\n      <td>32.179337</td>\n      <td>26.195923</td>\n      <td>-4.334152</td>\n      <td>6.599442</td>\n      <td>3.686600</td>\n      <td>0.0</td>\n      <td>2019-04-01 08:00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>104.90</td>\n      <td>19.92</td>\n      <td>0.532949</td>\n      <td>0.360718</td>\n      <td>0.238078</td>\n      <td>255.81377</td>\n      <td>260.79684</td>\n      <td>278.82367</td>\n      <td>259.3540</td>\n      <td>280.84116</td>\n      <td>...</td>\n      <td>-137404.0</td>\n      <td>0.601746</td>\n      <td>35.615920</td>\n      <td>35.005510</td>\n      <td>25.895142</td>\n      <td>-4.906418</td>\n      <td>6.482254</td>\n      <td>5.172928</td>\n      <td>0.0</td>\n      <td>2019-04-01 08:00:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 38 columns</p>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"HIMA_BANDS = ['B04B', 'B05B', 'B06B', 'B09B', 'B10B', 'B11B', 'B12B', 'B14B', 'B16B', 'I2B', 'I4B', 'IRB', 'VSB', 'WVB']\nERA5_PARAMS = ['CAPE', 'CIN', 'EWSS', 'IE', 'ISOR', 'KX', 'PEV', 'R250', 'R500', 'R850', 'SLHF', 'SLOR', 'SSHF', 'TCLW', 'TCW', 'TCWV', 'U250', 'U850', 'V250', 'V850']\nSELECTED_HIMA_BANDS = [ 'B05B', 'B06B',  'B10B', 'B11B', 'B12B',  'I4B', 'IRB']\nSELECTED_ERA5_PARAMS = ['CAPE', 'CIN', 'EWSS', 'IE', 'ISOR', 'KX', 'PEV', 'R250', 'R500', 'R850', 'SLHF', 'SLOR', 'SSHF', 'TCLW', 'TCW', 'TCWV', 'U250', 'U850', 'V250', 'V850']\nSELECTED_FEATURES = SELECTED_HIMA_BANDS + SELECTED_ERA5_PARAMS\nHEIGHT, WIDTH = 90, 250","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T02:27:40.212838Z","iopub.execute_input":"2025-05-05T02:27:40.213047Z","iopub.status.idle":"2025-05-05T02:27:40.217972Z","shell.execute_reply.started":"2025-05-05T02:27:40.213032Z","shell.execute_reply":"2025-05-05T02:27:40.217277Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom abc import ABC, abstractmethod\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport xgboost as xgb\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom cuml.ensemble import RandomForestRegressor\n\nclass BaseModel(ABC):\n    def __init__(self, selected_features):\n        self.selected_features = selected_features\n        self.feature_names = None\n\n    def _filter_features(self, X):\n        if isinstance(X, pd.DataFrame):\n            missing = set(self.selected_features) - set(X.columns)\n            if missing:\n                raise ValueError(f\"Missing features: {missing}\")\n            return X[self.selected_features]\n        elif isinstance(X, np.ndarray):\n            if self.feature_names is None:\n                raise ValueError(\"Feature names chưa được định nghĩa cho numpy array\")\n            X_df = pd.DataFrame(X, columns=self.feature_names)\n            return X_df[self.selected_features].values\n        else:\n            raise TypeError(\"Đầu vào phải là DataFrame hoặc numpy array\")\n\n    @abstractmethod\n    def fit(self, X, y): pass\n\n    @abstractmethod\n    def predict(self, X): pass\n\nclass XGBModel(BaseModel):\n    def __init__(self, selected_features, params=None, n_splits=5, early_stopping_rounds=20):\n        super().__init__(selected_features)\n        default_params = {\n            \"objective\": \"reg:squarederror\",\n            \"tree_method\": \"hist\",\n            \"device\" : \"cuda\",\n            \"n_estimators\": 1000,\n            \"learning_rate\": 0.05,\n            \"max_depth\": 8,\n            \"subsample\": 0.8,\n            \"colsample_bytree\": 0.8,\n            \"random_state\": 42\n        }\n        self.params = {**default_params, **(params or {})}\n        self.n_splits = n_splits\n        self.early_stopping_rounds = early_stopping_rounds\n        self.model = None\n        self.eval_metric = \"rmse\"\n\n    def fit(self, X, y, eval_set=None, eval_metric=None, verbose=False):\n        # Store feature names\n        if isinstance(X, pd.DataFrame):\n            self.feature_names = X.columns.tolist()\n        X_filtered = self._filter_features(X)\n\n        # Determine train/val for early stopping\n        fit_X, fit_y = X_filtered, y\n        ev_set = None\n        if eval_set is None:\n            kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n            train_idx, val_idx = next(kf.split(X_filtered))\n            fit_X = X_filtered.iloc[train_idx]\n            fit_y = y.iloc[train_idx] if isinstance(y, pd.Series) else y[train_idx]\n            X_val = X_filtered.iloc[val_idx]\n            y_val = y.iloc[val_idx] if isinstance(y, pd.Series) else y[val_idx]\n            ev_set = [(X_val, y_val)]\n        else:\n            X_val, y_val = eval_set\n            X_val_filtered = self._filter_features(X_val)\n            ev_set = [(X_val_filtered, y_val)]\n\n        # Initialize and train\n        self.model = xgb.XGBRegressor(**self.params)\n        fit_kwargs = {\n            \"eval_metric\": eval_metric or self.eval_metric,\n            \"verbose\": verbose\n        }\n        if ev_set is not None:\n            fit_kwargs.update({\n                \"eval_set\": ev_set,\n                \"early_stopping_rounds\": self.early_stopping_rounds\n            })\n        self.model.fit(fit_X, fit_y, **fit_kwargs)\n\n    def predict(self, X):\n        X_filtered = self._filter_features(X)\n        return self.model.predict(X_filtered)\n\nclass DNNModel(BaseModel):\n    def __init__(self, selected_features, layers=(64, 32)):\n        super().__init__(selected_features)\n        self.input_dim = len(selected_features)\n        self.layers = layers\n        self.model = self._build_model()\n\n    def _build_model(self):\n        model = Sequential()\n        model.add(Dense(self.layers[0], activation=\"relu\", input_dim=self.input_dim))\n        for units in self.layers[1:]:\n            model.add(Dense(units, activation=\"relu\"))\n        model.add(Dense(1))\n        return model\n\n    def fit(self, X, y, epochs=50, batch_size=32):\n        if isinstance(X, pd.DataFrame):\n            self.feature_names = X.columns.tolist()\n        X_filtered = self._filter_features(X)\n        self.model.compile(optimizer=\"adam\", loss=\"mse\")\n        self.model.fit(X_filtered, y, epochs=epochs, batch_size=batch_size, verbose=0)\n\n    def predict(self, X):\n        X_filtered = self._filter_features(X)\n        return self.model.predict(X_filtered).flatten()\n\nclass ERTModel(BaseModel):\n    def __init__(self, selected_features, params=None):\n        super().__init__(selected_features)\n        default_params = {\"n_estimators\": 100, \"max_features\": 1.0, \"n_streams\": 1}\n        self.params = {**default_params, **(params or {})}\n        self.model = RandomForestRegressor(**self.params)\n\n    def fit(self, X, y):\n        if isinstance(X, pd.DataFrame):\n            self.feature_names = X.columns.tolist()\n        X_filtered = self._filter_features(X)\n        self.model.fit(X_filtered, y)\n\n    def predict(self, X):\n        X_filtered = self._filter_features(X)\n        return self.model.predict(X_filtered)\n\nclass StackingModel:\n    def __init__(self, level1_models, level2_model, n_folds=5):\n        self.n_folds = n_folds\n        self.level1_models = level1_models\n        self.level2_model = level2_model\n\n    def _generate_meta_features(self, X, y):\n        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n        meta = np.zeros((X.shape[0], len(self.level1_models)))\n        for i, model in enumerate(self.level1_models):\n            for train_idx, val_idx in kf.split(X):\n                Xi_tr, Xi_val = X[train_idx], X[val_idx]\n                yi_tr = y[train_idx]\n                df_tr = pd.DataFrame(Xi_tr, columns=model.feature_names)\n                df_val = pd.DataFrame(Xi_val, columns=model.feature_names)\n                model.fit(df_tr, yi_tr)\n                meta[val_idx, i] = model.predict(df_val)\n        return meta\n\n    def fit(self, X, y):\n        meta = self._generate_meta_features(X.values, y.values)\n        self.level2_model.fit(meta, y.values)\n\n    def predict(self, X):\n        preds = []\n        for m in self.level1_models:\n            dfX = pd.DataFrame(X, columns=m.feature_names)\n            preds.append(m.predict(dfX))\n        meta_test = np.column_stack(preds)\n        return self.level2_model.predict(meta_test)\n\n# ========== Main pipeline ==========\ndf = pd.read_csv(\"/kaggle/input/data-full-features-ai/weather_data_nghean (1).csv\")\ndf.fillna(df.mean(numeric_only=True), inplace=True)\n\nTARGET_COL = \"Radar\"\nHIMA_SELECTED = ['B05B','B06B','B11B','B12B','I2B','I4B','IRB']\nERA5_SELECTED = ['CAPE','CIN','EWSS','IE','ISOR','KX','PEV','R250','R500','R850','SLHF','SLOR','SSHF','TCLW','TCW','TCWV','U250','U850','V250','V850']\nFOR_XG = HIMA_SELECTED + ERA5_SELECTED\nALL_FEATURES = FOR_XG\n\nX = df[ALL_FEATURES]\ny = df[TARGET_COL]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nxgb_model = XGBModel(selected_features=FOR_XG, params={\"n_estimators\":200,\"max_depth\":6}, n_splits=5, early_stopping_rounds=20)\ndnn_model = DNNModel(selected_features=ALL_FEATURES, layers=(128,64,32))\nert_model = ERTModel(selected_features=ALL_FEATURES, params={\"n_estimators\":100})\n\n# Train\nxgb_model.fit(X_train, y_train)\ndnn_model.fit(X_train, y_train)\nert_model.fit(X_train, y_train)\n\n# Evaluate level-1 models\ndef evaluate_model(m, X_t, y_t):\n    dfX = X_t if isinstance(X_t, pd.DataFrame) else pd.DataFrame(X_t, columns=m.feature_names)\n    preds = m.predict(dfX)\n    return mean_absolute_error(y_t, preds), mean_squared_error(y_t, preds), np.sqrt(mean_squared_error(y_t, preds)), r2_score(y_t, preds)\n\nmetrics = {}\nfor name, model in [('XGB', xgb_model), ('DNN', dnn_model), ('ERT', ert_model)]:\n    metrics[name] = evaluate_model(model, X_test, y_test)\nprint(\"Level-1 metrics:\", metrics)\n\n# Stacking\nmeta_model = ElasticNet(alpha=0.01, l1_ratio=0.7)\nstacker = StackingModel([xgb_model, dnn_model, ert_model], meta_model, n_folds=5)\nstacker.fit(X_train, y_train)\npreds_stack = stacker.predict(X_test)\nmae_s, mse_s, rmse_s, r2_s = mean_absolute_error(y_test, preds_stack), mean_squared_error(y_test, preds_stack), np.sqrt(mean_squared_error(y_test, preds_stack)), r2_score(y_test, preds_stack)\nprint(\"Stacking metrics: MAE=%.4f, RMSE=%.4f, R2=%.4f\" % (mae_s, rmse_s, r2_s))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T02:27:40.219168Z","iopub.execute_input":"2025-05-05T02:27:40.219356Z","iopub.status.idle":"2025-05-05T03:14:08.453873Z","shell.execute_reply.started":"2025-05-05T02:27:40.219342Z","shell.execute_reply":"2025-05-05T03:14:08.453187Z"}},"outputs":[{"name":"stderr","text":"2025-05-05 02:27:42.269553: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746412062.451512      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746412062.503654      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\nI0000 00:00:1746412083.928707      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1746412083.929372      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1746412088.833687      98 service.cc:148] XLA service 0x7be268003100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1746412088.834254      98 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1746412088.834273      98 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1746412089.037028      98 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1746412089.837658      98 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [02:37:13] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2429/2429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\nLevel-1 metrics: {'XGB': (0.1657905744887403, 0.580675357452941, 0.762020575478734, 0.6678814111779581), 'DNN': (0.3667747476753957, 1.7485716650856988, 1.3223356854769135, -9.953308468735322e-05), 'ERT': (0.12144270672808426, 0.46118816314524935, 0.6791083589128095, 0.7362223831968917)}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n\u001b[1m2429/2429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\nStacking metrics: MAE=0.1300, RMSE=0.7099, R2=0.7118\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}