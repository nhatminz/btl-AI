{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11237152,"sourceType":"datasetVersion","datasetId":7020161}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install GDAL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:07.205615Z","iopub.execute_input":"2025-05-01T04:50:07.205948Z","iopub.status.idle":"2025-05-01T04:50:11.075216Z","shell.execute_reply.started":"2025-05-01T04:50:07.205908Z","shell.execute_reply":"2025-05-01T04:50:11.074510Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: GDAL in /usr/local/lib/python3.11/dist-packages (3.6.4)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom osgeo import gdal\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nimport glob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:11.076471Z","iopub.execute_input":"2025-05-01T04:50:11.076702Z","iopub.status.idle":"2025-05-01T04:50:16.571085Z","shell.execute_reply.started":"2025-05-01T04:50:11.076683Z","shell.execute_reply":"2025-05-01T04:50:16.570317Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.571908Z","iopub.execute_input":"2025-05-01T04:50:16.572292Z","iopub.status.idle":"2025-05-01T04:50:16.660769Z","shell.execute_reply.started":"2025-05-01T04:50:16.572274Z","shell.execute_reply":"2025-05-01T04:50:16.659949Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Đặt seed để tái lập kết quả\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Định nghĩa các hằng số và đường dẫn\nBASE_PATH = \"/kaggle/input/btl-ai/DATA_SV\"\nHIMA_PATH = os.path.join(BASE_PATH, \"Hima\")\nERA5_PATH = os.path.join(BASE_PATH, \"ERA5\")\nPRECIP_PATH = os.path.join(BASE_PATH, \"Precipitation/Radar\")\nOUTPUT_PATH = \"/kaggle/working/output/\"\nos.makedirs(OUTPUT_PATH, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.662627Z","iopub.execute_input":"2025-05-01T04:50:16.663332Z","iopub.status.idle":"2025-05-01T04:50:16.676562Z","shell.execute_reply.started":"2025-05-01T04:50:16.663312Z","shell.execute_reply":"2025-05-01T04:50:16.675880Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"HIMA_BANDS = ['B04B', 'B05B', 'B06B', 'B09B', 'B10B', 'B11B', 'B12B', 'B14B', 'B16B', 'I2B', 'I4B', 'IRB', 'VSB', 'WVB']  # 14 band\nERA5_PARAMS = ['CAPE', 'CIN', 'EWSS', 'IE', 'ISOR', 'KX', 'PEV', 'R250', 'R500', 'R850', 'SLHF', 'SLOR', 'SSHF', 'TCLW', 'TCW', 'TCWV', 'U250', 'U850', 'V250', 'V850']  # 20 tham số\nSELECTED_FEATURES = ['B04B', 'B10B', 'B11B', 'B16B', 'IRB', 'CAPE', 'R500', 'R850', 'TCWV', 'U850', 'I2B', 'TCLW', 'TCW' ]  # Giả định các đặc trưng có tương quan cao\nHEIGHT, WIDTH = 90, 250\nHEIGHT, WIDTH = 90, 250\nin_channel = len(SELECTED_FEATURES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.677288Z","iopub.execute_input":"2025-05-01T04:50:16.677485Z","iopub.status.idle":"2025-05-01T04:50:16.683103Z","shell.execute_reply.started":"2025-05-01T04:50:16.677460Z","shell.execute_reply":"2025-05-01T04:50:16.682407Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Hàm đọc file GeoTIFF\ndef read_geotiff(file_path):\n    try:\n        ds = gdal.Open(file_path)\n        band = ds.GetRasterBand(1)\n        data = band.ReadAsArray()\n        ds = None\n        if data.shape != (HEIGHT, WIDTH):\n            print(f\"Invalid shape {data.shape} for file {file_path}, expected ({HEIGHT}, {WIDTH})\")\n            return None\n        return data\n    except Exception as e:\n        print(f\"Error reading {file_path}: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.683858Z","iopub.execute_input":"2025-05-01T04:50:16.684109Z","iopub.status.idle":"2025-05-01T04:50:16.697355Z","shell.execute_reply.started":"2025-05-01T04:50:16.684092Z","shell.execute_reply":"2025-05-01T04:50:16.696644Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Hàm phân tích thời gian từ tên file\ndef parse_datetime_from_filename(filename, data_type):\n    try:\n        if data_type == \"Hima\":\n            parts = filename.split('_')\n            if len(parts) < 2:\n                return None\n            time_part = parts[1].split('_TB.tif')[0]\n            time_part = time_part.replace('.Z', '')\n            dt = datetime.strptime(time_part, '%Y%m%d%H%M')\n        elif data_type == \"ERA5\":\n            parts = filename.split('_')\n            if len(parts) < 2:\n                return None\n            time_part = parts[1].replace('.tif', '')\n            dt = datetime.strptime(time_part, '%Y%m%d%H%M%S')\n        elif data_type == \"Radar\":\n            time_part = filename.split('_')[1].replace('.tif', '')\n            dt = datetime.strptime(time_part, '%Y%m%d%H%M%S')\n        else:\n            return None\n        return dt.replace(minute=0, second=0, microsecond=0)\n    except Exception as e:\n        global error_count\n        if error_count < 5:\n            print(f\"Error parsing datetime from {filename} (type {data_type}): {e}\")\n            error_count += 1\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.698033Z","iopub.execute_input":"2025-05-01T04:50:16.698226Z","iopub.status.idle":"2025-05-01T04:50:16.709423Z","shell.execute_reply.started":"2025-05-01T04:50:16.698211Z","shell.execute_reply":"2025-05-01T04:50:16.708872Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"error_count = 0\n\n# Hàm thu thập file\ndef collect_files(base_path, expected_subdirs=None, data_type=None):\n    files_dict = {}\n    file_count = 0\n    for root, dirs, files in os.walk(base_path):\n        for file in files:\n            if file.endswith('.tif'):\n                file_path = os.path.join(root, file)\n                dt = parse_datetime_from_filename(file, data_type)\n                if dt is None:\n                    continue\n                file_count += 1\n                if expected_subdirs:\n                    subdir = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(file_path)))))\n                    if dt not in files_dict:\n                        files_dict[dt] = {}\n                    files_dict[dt][subdir] = file_path\n                else:\n                    files_dict[dt] = file_path\n    print(f\"Found {file_count} files in {base_path}\")\n    return files_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.710286Z","iopub.execute_input":"2025-05-01T04:50:16.710466Z","iopub.status.idle":"2025-05-01T04:50:16.725821Z","shell.execute_reply.started":"2025-05-01T04:50:16.710449Z","shell.execute_reply":"2025-05-01T04:50:16.725310Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Hàm xử lý dữ liệu thiếu và chuẩn hóa\ndef preprocess_data(data, data_type):\n    if data is None:\n        return None\n    # Xử lý giá trị không hợp lệ bằng nội suy\n    if np.any(np.isinf(data) | np.isnan(data) | (data == -9999)):\n        mask = np.isinf(data) | np.isnan(data) | (data == -9999)\n        x, y = np.indices(data.shape)\n        valid_points = np.column_stack((x[~mask], y[~mask]))\n        valid_values = data[~mask]\n        invalid_points = np.column_stack((x[mask], y[mask]))\n        if len(valid_values) > 0:\n            interpolated_values = griddata(valid_points, valid_values, invalid_points, method='nearest')\n            data[mask] = interpolated_values\n        else:\n            data[mask] = 0  # Nếu không có giá trị hợp lệ, điền 0\n    if data_type == \"Radar\":\n        # Log transformation cho radar\n        data = np.log1p(np.maximum(data, 0))  # log(1 + x)\n    else:\n        # Min-max scaling cho Himawari và ERA5\n        data_min, data_max = np.min(data), np.max(data)\n        if data_max > data_min:\n            data = (data - data_min) / (data_max - data_min)\n        else:\n            data = np.zeros_like(data)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.726536Z","iopub.execute_input":"2025-05-01T04:50:16.727123Z","iopub.status.idle":"2025-05-01T04:50:16.738239Z","shell.execute_reply.started":"2025-05-01T04:50:16.727105Z","shell.execute_reply":"2025-05-01T04:50:16.737704Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Hàm tạo chuỗi thời gian t-4 đến t\ndef create_time_sequences(hima_files, era5_files, precip_files, common_datetimes):\n    X, y = [], []\n    for i in range(4, len(common_datetimes)):\n        dt = common_datetimes[i]\n        # Kiểm tra tính liên tục của 5 khung\n        valid_sequence = True\n        for j in range(1, 5):\n            if common_datetimes[i-j] != dt - timedelta(hours=j):\n                valid_sequence = False\n                break\n        if not valid_sequence:\n            continue\n\n        # Tạo chuỗi 5 khung\n        sequence = []\n        for j in range(5):\n            dt_j = common_datetimes[i-j]\n            # Đọc Himawari (chỉ các band được chọn)\n            hima_data = []\n            for band in [b for b in HIMA_BANDS if b in SELECTED_FEATURES]:\n                file_path = hima_files.get(dt_j, {}).get(band)\n                if not file_path:\n                    valid_sequence = False\n                    break\n                data = read_geotiff(file_path)\n                data = preprocess_data(data, \"Hima\")\n                if data is None:\n                    valid_sequence = False\n                    break\n                hima_data.append(data)\n            if not valid_sequence:\n                break\n\n            # Đọc ERA5 (chỉ các tham số được chọn)\n            era5_data = []\n            for param in [p for p in ERA5_PARAMS if p in SELECTED_FEATURES]:\n                file_path = era5_files.get(dt_j, {}).get(param)\n                if not file_path:\n                    valid_sequence = False\n                    break\n                data = read_geotiff(file_path)\n                data = preprocess_data(data, \"ERA5\")\n                if data is None:\n                    valid_sequence = False\n                    break\n                era5_data.append(data)\n            if not valid_sequence:\n                break\n\n            # Kết hợp Himawari và ERA5\n            combined = np.concatenate([np.stack(hima_data, axis=-1), np.stack(era5_data, axis=-1)], axis=-1)  # (90, 250, 10)\n            sequence.append(combined)\n        if not valid_sequence:\n            continue\n\n        # Đọc radar (ground truth)\n        radar_file = precip_files.get(dt)\n        if not radar_file:\n            continue\n        radar_data = read_geotiff(radar_file)\n        radar_data = preprocess_data(radar_data, \"Radar\")\n        if radar_data is None:\n            continue\n\n        sequence = np.stack(sequence, axis=0)  # (5, 90, 250, 10)\n        X.append(sequence)\n        y.append(radar_data)  # (90, 250)\n\n    X = np.array(X)\n    y = np.array(y)\n    # Chuyển đổi định dạng để kênh nằm trước chiều không gian\n    X = X.transpose(0, 1, 4, 2, 3)  # (samples, 5, 10, 90, 250)\n    return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.752001Z","iopub.execute_input":"2025-05-01T04:50:16.752494Z","iopub.status.idle":"2025-05-01T04:50:16.764245Z","shell.execute_reply.started":"2025-05-01T04:50:16.752472Z","shell.execute_reply":"2025-05-01T04:50:16.763652Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Định nghĩa lớp ConvLSTMCell tùy chỉnh\nclass ConvLSTMCell(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, padding):\n        super(ConvLSTMCell, self).__init__()\n        self.out_channels = out_channels\n        self.conv = nn.Conv2d(\n            in_channels + out_channels, 4 * out_channels, kernel_size,\n            padding=padding, bias=True\n        )\n\n    def forward(self, x, h_prev, c_prev):\n        combined = torch.cat([x, h_prev], dim=1)\n        conv_out = self.conv(combined)\n        i, f, o, g = torch.chunk(conv_out, 4, dim=1)\n        i = torch.sigmoid(i)\n        f = torch.sigmoid(f)\n        o = torch.sigmoid(o)\n        g = torch.tanh(g)\n        c_next = f * c_prev + i * g\n        h_next = o * torch.tanh(c_next)\n        return h_next, c_next","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.764928Z","iopub.execute_input":"2025-05-01T04:50:16.765169Z","iopub.status.idle":"2025-05-01T04:50:16.778342Z","shell.execute_reply.started":"2025-05-01T04:50:16.765149Z","shell.execute_reply":"2025-05-01T04:50:16.777697Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Định nghĩa lớp ConvLSTM2d\nclass ConvLSTM2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, padding):\n        super(ConvLSTM2d, self).__init__()\n        self.cell = ConvLSTMCell(in_channels, out_channels, kernel_size, padding)\n\n    def forward(self, x):\n        if len(x.size()) == 5:\n            batch, seq_len, channels, height, width = x.size()\n            is_sequence = True\n        elif len(x.size()) == 4:\n            batch, channels, height, width = x.size()\n            seq_len = 1\n            x = x.unsqueeze(1)\n            is_sequence = False\n        else:\n            raise ValueError(f\"Expected 4 or 5 dimensions, got {len(x.size())}\")\n\n        out_channels = self.cell.out_channels\n        h = torch.zeros(batch, out_channels, height, width, device=x.device)\n        c = torch.zeros(batch, out_channels, height, width, device=x.device)\n        outputs = []\n        for t in range(seq_len):\n            x_t = x[:, t, :, :, :]\n            h, c = self.cell(x_t, h, c)\n            outputs.append(h)\n        output = outputs[-1] if is_sequence else h\n        return output, (h, c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.778997Z","iopub.execute_input":"2025-05-01T04:50:16.779206Z","iopub.status.idle":"2025-05-01T04:50:16.791860Z","shell.execute_reply.started":"2025-05-01T04:50:16.779183Z","shell.execute_reply":"2025-05-01T04:50:16.791057Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Hàm huấn luyện mô hình\ndef train_model(model, train_loader, val_loader, epochs=30, patience=7):\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n    best_loss = float('inf')\n    patience_counter = 0\n    best_model_state = None\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n        for X_batch, y_batch in train_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            optimizer.zero_grad()\n            output = model(X_batch)\n            loss = criterion(output, y_batch)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * X_batch.size(0)\n        train_loss /= len(train_loader.dataset)\n\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                output = model(X_batch)\n                loss = criterion(output, y_batch)\n                val_loss += loss.item() * X_batch.size(0)\n            val_loss /= len(val_loader.dataset)\n\n        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, LR: {optimizer.param_groups[0]['lr']}\")\n        scheduler.step(val_loss)\n\n        if val_loss < best_loss:\n            best_loss = val_loss\n            best_model_state = model.state_dict()\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(\"Early stopping\")\n                break\n\n    model.load_state_dict(best_model_state)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.792675Z","iopub.execute_input":"2025-05-01T04:50:16.792908Z","iopub.status.idle":"2025-05-01T04:50:16.806987Z","shell.execute_reply.started":"2025-05-01T04:50:16.792892Z","shell.execute_reply":"2025-05-01T04:50:16.806275Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Định nghĩa mô hình ConvLSTM\nclass ConvLSTMModel(nn.Module):\n    def __init__(self):\n        super(ConvLSTMModel, self).__init__()\n        self.convlstm1 = ConvLSTM2d(in_channels=in_channel, out_channels=64, kernel_size=(5, 5), padding=(2, 2))  # in_channels=10\n        self.bn1 = nn.BatchNorm2d(64)\n        self.convlstm2 = ConvLSTM2d(in_channels=64, out_channels=32, kernel_size=(5, 5), padding=(2, 2))\n        self.bn2 = nn.BatchNorm2d(32)\n        self.dropout = nn.Dropout(0.2)\n        self.conv = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=(3, 3), padding=(1, 1))\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x, _ = self.convlstm1(x)\n        x = self.bn1(x)\n        x, _ = self.convlstm2(x)\n        x = self.bn2(x)\n        x = self.dropout(x)\n        x = self.conv(x)\n        x = self.relu(x)\n        return x.squeeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.807778Z","iopub.execute_input":"2025-05-01T04:50:16.808015Z","iopub.status.idle":"2025-05-01T04:50:16.819498Z","shell.execute_reply.started":"2025-05-01T04:50:16.807996Z","shell.execute_reply":"2025-05-01T04:50:16.818982Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Hàm tính chỉ số đánh giá\ndef evaluate_model(y_true, y_pred, threshold=1.0):\n    y_true_original = np.expm1(y_true)  # Chuyển về thang gốc\n    y_pred_original = np.expm1(y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true_original.flatten(), y_pred_original.flatten()))\n    corr = np.corrcoef(y_true_original.flatten(), y_pred_original.flatten())[0, 1] if np.std(y_true_original) > 0 and np.std(y_pred_original) > 0 else 0\n\n    y_true_bin = (y_true_original > threshold).astype(int)\n    y_pred_bin = (y_pred_original > threshold).astype(int)\n    hits = np.sum((y_true_bin == 1) & (y_pred_bin == 1))\n    misses = np.sum((y_true_bin == 1) & (y_pred_bin == 0))\n    false_alarms = np.sum((y_true_bin == 0) & (y_pred_bin == 1))\n    true_negatives = np.sum((y_true_bin == 0) & (y_pred_bin == 0))\n    total = hits + misses + false_alarms + true_negatives\n\n    accuracy = (hits + true_negatives) / total if total > 0 else 0\n    csi = hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0\n    far = false_alarms / (hits + false_alarms) if (hits + false_alarms) > 0 else 0\n    hss = (2 * (hits * true_negatives - misses * false_alarms)) / \\\n          ((hits + misses) * (misses + true_negatives) + (hits + false_alarms) * (false_alarms + true_negatives)) \\\n          if ((hits + misses) * (misses + true_negatives) + (hits + false_alarms) * (false_alarms + true_negatives)) > 0 else 0\n    ets = ((hits - ((hits + misses) * (hits + false_alarms) / total)) / \\\n           (hits + misses + false_alarms - ((hits + misses) * (hits + false_alarms) / total))) \\\n          if (hits + misses + false_alarms - ((hits + misses) * (hits + false_alarms) / total)) > 0 else 0\n\n    return {'rmse': rmse, 'corr': corr, 'accuracy': accuracy, 'csi': csi, 'far': far, 'hss': hss, 'ets': ets}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.820315Z","iopub.execute_input":"2025-05-01T04:50:16.820640Z","iopub.status.idle":"2025-05-01T04:50:16.832811Z","shell.execute_reply.started":"2025-05-01T04:50:16.820606Z","shell.execute_reply":"2025-05-01T04:50:16.832140Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Hàm vẽ scatter plot\ndef plot_scatter(y_true, y_pred, output_path):\n    plt.figure(figsize=(8, 6))\n    plt.scatter(y_true.flatten(), y_pred.flatten(), alpha=0.5)\n    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n    plt.xlabel('Ground Truth (mm/h)')\n    plt.ylabel('Predicted (mm/h)')\n    plt.title('Scatter Plot: Predicted vs Ground Truth')\n    plt.savefig(output_path)\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.833490Z","iopub.execute_input":"2025-05-01T04:50:16.834236Z","iopub.status.idle":"2025-05-01T04:50:16.847262Z","shell.execute_reply.started":"2025-05-01T04:50:16.834218Z","shell.execute_reply":"2025-05-01T04:50:16.846537Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Hàm hiển thị bản đồ\ndef plot_rainfall_map(y_true, y_pred, output_path):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n    ax1.set_title('Ground Truth')\n    ax2.set_title('Prediction')\n    for ax, data in [(ax1, y_true), (ax2, y_pred)]:\n        ax.coastlines()\n        ax.add_feature(cfeature.BORDERS)\n        im = ax.imshow(data, cmap='Blues', origin='upper', transform=ccrs.PlateCarree())\n        plt.colorbar(im, ax=ax, label='Rainfall (mm/h)')\n    plt.savefig(output_path)\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.847992Z","iopub.execute_input":"2025-05-01T04:50:16.848346Z","iopub.status.idle":"2025-05-01T04:50:16.862289Z","shell.execute_reply.started":"2025-05-01T04:50:16.848320Z","shell.execute_reply":"2025-05-01T04:50:16.861796Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Hàm lưu GeoTIFF\ndef save_geotiff(data, output_path, reference_file):\n    ds = gdal.Open(reference_file)\n    driver = gdal.GetDriverByName('GTiff')\n    out_ds = driver.Create(output_path, WIDTH, HEIGHT, 1, gdal.GDT_Float32)\n    out_ds.SetGeoTransform(ds.GetGeoTransform())\n    out_ds.SetProjection(ds.GetProjection())\n    out_band = out_ds.GetRasterBand(1)\n    out_band.WriteArray(data)\n    out_band.FlushCache()\n    out_ds = None\n    ds = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.862981Z","iopub.execute_input":"2025-05-01T04:50:16.863250Z","iopub.status.idle":"2025-05-01T04:50:16.874044Z","shell.execute_reply.started":"2025-05-01T04:50:16.863226Z","shell.execute_reply":"2025-05-01T04:50:16.873301Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Bắt đầu chương trình\nprint(\"Collecting Himawari files...\")\nhima_files = {}\nfor band in HIMA_BANDS:\n    band_path = os.path.join(HIMA_PATH, band)\n    if not os.path.exists(band_path):\n        print(f\"Directory not found: {band_path}\")\n        continue\n    band_files = collect_files(band_path, expected_subdirs=HIMA_BANDS, data_type=\"Hima\")\n    for dt, paths in band_files.items():\n        if dt not in hima_files:\n            hima_files[dt] = {}\n        hima_files[dt][band] = paths[band]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:16.874794Z","iopub.execute_input":"2025-05-01T04:50:16.875094Z","iopub.status.idle":"2025-05-01T04:50:52.825364Z","shell.execute_reply.started":"2025-05-01T04:50:16.875073Z","shell.execute_reply":"2025-05-01T04:50:52.824583Z"}},"outputs":[{"name":"stdout","text":"Collecting Himawari files...\nFound 1438 files in /kaggle/input/btl-ai/DATA_SV/Hima/B04B\nFound 1361 files in /kaggle/input/btl-ai/DATA_SV/Hima/B05B\nFound 1158 files in /kaggle/input/btl-ai/DATA_SV/Hima/B06B\nFound 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B09B\nFound 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B10B\nFound 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B11B\nFound 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B12B\nFound 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/B14B\nFound 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/B16B\nFound 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/I2B\nFound 2673 files in /kaggle/input/btl-ai/DATA_SV/Hima/I4B\nFound 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/IRB\nFound 1448 files in /kaggle/input/btl-ai/DATA_SV/Hima/VSB\nFound 2774 files in /kaggle/input/btl-ai/DATA_SV/Hima/WVB\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(\"Collecting ERA5 files...\")\nera5_files = {}\nfor param in ERA5_PARAMS:\n    param_path = os.path.join(ERA5_PATH, param)\n    if not os.path.exists(param_path):\n        print(f\"Directory not found: {param_path}\")\n        continue\n    param_files = collect_files(param_path, expected_subdirs=ERA5_PARAMS, data_type=\"ERA5\")\n    for dt, paths in param_files.items():\n        if dt not in era5_files:\n            era5_files[dt] = {}\n        era5_files[dt][param] = paths[param]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:50:52.826210Z","iopub.execute_input":"2025-05-01T04:50:52.826471Z","iopub.status.idle":"2025-05-01T04:52:11.052395Z","shell.execute_reply.started":"2025-05-01T04:50:52.826448Z","shell.execute_reply":"2025-05-01T04:52:11.051733Z"}},"outputs":[{"name":"stdout","text":"Collecting ERA5 files...\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/CAPE\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/CIN\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/EWSS\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/IE\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/ISOR\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/KX\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/PEV\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/R250\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/R500\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/R850\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/SLHF\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/SLOR\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/SSHF\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/TCLW\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/TCW\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/TCWV\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/U250\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/U850\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/V250\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/V850\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(\"Collecting Precipitation files...\")\nprecip_files = collect_files(PRECIP_PATH, data_type=\"Radar\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:52:11.053179Z","iopub.execute_input":"2025-05-01T04:52:11.053921Z","iopub.status.idle":"2025-05-01T04:52:14.629029Z","shell.execute_reply.started":"2025-05-01T04:52:11.053901Z","shell.execute_reply":"2025-05-01T04:52:14.628293Z"}},"outputs":[{"name":"stdout","text":"Collecting Precipitation files...\nFound 2487 files in /kaggle/input/btl-ai/DATA_SV/Precipitation/Radar\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Đồng bộ thời gian\ncommon_datetimes = set(hima_files.keys()) & set(era5_files.keys()) & set(precip_files.keys())\ncommon_datetimes = sorted(list(common_datetimes))\nprint(f\"Số thời điểm đồng bộ: {len(common_datetimes)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:52:14.629810Z","iopub.execute_input":"2025-05-01T04:52:14.630098Z","iopub.status.idle":"2025-05-01T04:52:14.642520Z","shell.execute_reply.started":"2025-05-01T04:52:14.630080Z","shell.execute_reply":"2025-05-01T04:52:14.641563Z"}},"outputs":[{"name":"stdout","text":"Số thời điểm đồng bộ: 2337\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from scipy.interpolate import griddata\n# Tạo chuỗi thời gian\nprint(\"Creating time sequences...\")\nX, y = create_time_sequences(hima_files, era5_files, precip_files, common_datetimes)\nprint(f\"X shape: {X.shape}, y shape: {y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:52:14.643265Z","iopub.execute_input":"2025-05-01T04:52:14.643522Z","iopub.status.idle":"2025-05-01T04:57:56.866997Z","shell.execute_reply.started":"2025-05-01T04:52:14.643501Z","shell.execute_reply":"2025-05-01T04:57:56.866239Z"}},"outputs":[{"name":"stdout","text":"Creating time sequences...\nX shape: (720, 5, 13, 90, 250), y shape: (720, 90, 250)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Chia dữ liệu\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\nprint(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:57:56.867639Z","iopub.execute_input":"2025-05-01T04:57:56.867891Z","iopub.status.idle":"2025-05-01T04:57:58.459378Z","shell.execute_reply.started":"2025-05-01T04:57:56.867874Z","shell.execute_reply":"2025-05-01T04:57:58.458379Z"}},"outputs":[{"name":"stdout","text":"Train: (504, 5, 13, 90, 250), Val: (108, 5, 13, 90, 250), Test: (108, 5, 13, 90, 250)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Chuyển sang tensor\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.float32)\nX_val = torch.tensor(X_val, dtype=torch.float32)\ny_val = torch.tensor(y_val, dtype=torch.float32)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.float32)\n\n# Tạo DataLoader\ntrain_dataset = TensorDataset(X_train, y_train)\nval_dataset = TensorDataset(X_val, y_val)\ntest_dataset = TensorDataset(X_test, y_test)\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8)\ntest_loader = DataLoader(test_dataset, batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:57:58.460114Z","iopub.execute_input":"2025-05-01T04:57:58.460388Z","iopub.status.idle":"2025-05-01T04:58:00.413730Z","shell.execute_reply.started":"2025-05-01T04:57:58.460365Z","shell.execute_reply":"2025-05-01T04:58:00.413151Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Khởi tạo và huấn luyện mô hình\nmodel = ConvLSTMModel().to(device)\nmodel = train_model(model, train_loader, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T04:58:00.414432Z","iopub.execute_input":"2025-05-01T04:58:00.414634Z","iopub.status.idle":"2025-05-01T05:17:24.406937Z","shell.execute_reply.started":"2025-05-01T04:58:00.414619Z","shell.execute_reply":"2025-05-01T05:17:24.406048Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30, Train Loss: 0.0801, Val Loss: 0.0586, LR: 0.001\nEpoch 2/30, Train Loss: 0.0495, Val Loss: 0.0580, LR: 0.001\nEpoch 3/30, Train Loss: 0.0474, Val Loss: 0.0612, LR: 0.001\nEpoch 4/30, Train Loss: 0.0454, Val Loss: 0.0504, LR: 0.001\nEpoch 5/30, Train Loss: 0.0444, Val Loss: 0.0581, LR: 0.001\nEpoch 6/30, Train Loss: 0.0442, Val Loss: 0.0507, LR: 0.001\nEpoch 7/30, Train Loss: 0.0435, Val Loss: 0.0489, LR: 0.001\nEpoch 8/30, Train Loss: 0.0432, Val Loss: 0.0491, LR: 0.001\nEpoch 9/30, Train Loss: 0.0434, Val Loss: 0.0545, LR: 0.001\nEpoch 10/30, Train Loss: 0.0429, Val Loss: 0.0495, LR: 0.001\nEpoch 11/30, Train Loss: 0.0426, Val Loss: 0.0489, LR: 0.001\nEpoch 12/30, Train Loss: 0.0413, Val Loss: 0.0480, LR: 0.0005\nEpoch 13/30, Train Loss: 0.0422, Val Loss: 0.0532, LR: 0.0005\nEpoch 14/30, Train Loss: 0.0428, Val Loss: 0.0477, LR: 0.0005\nEpoch 15/30, Train Loss: 0.0413, Val Loss: 0.0483, LR: 0.0005\nEpoch 16/30, Train Loss: 0.0409, Val Loss: 0.0486, LR: 0.0005\nEpoch 17/30, Train Loss: 0.0414, Val Loss: 0.0495, LR: 0.0005\nEpoch 18/30, Train Loss: 0.0410, Val Loss: 0.0496, LR: 0.0005\nEpoch 19/30, Train Loss: 0.0407, Val Loss: 0.0503, LR: 0.00025\nEpoch 20/30, Train Loss: 0.0405, Val Loss: 0.0472, LR: 0.00025\nEpoch 21/30, Train Loss: 0.0404, Val Loss: 0.0476, LR: 0.00025\nEpoch 22/30, Train Loss: 0.0402, Val Loss: 0.0480, LR: 0.00025\nEpoch 23/30, Train Loss: 0.0396, Val Loss: 0.0467, LR: 0.00025\nEpoch 24/30, Train Loss: 0.0398, Val Loss: 0.0487, LR: 0.00025\nEpoch 25/30, Train Loss: 0.0396, Val Loss: 0.0465, LR: 0.00025\nEpoch 26/30, Train Loss: 0.0399, Val Loss: 0.0471, LR: 0.00025\nEpoch 27/30, Train Loss: 0.0394, Val Loss: 0.0471, LR: 0.00025\nEpoch 28/30, Train Loss: 0.0388, Val Loss: 0.0480, LR: 0.00025\nEpoch 29/30, Train Loss: 0.0394, Val Loss: 0.0464, LR: 0.00025\nEpoch 30/30, Train Loss: 0.0392, Val Loss: 0.0461, LR: 0.00025\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Đánh giá trên tập kiểm thử\nmodel.eval()\ny_pred = []\nwith torch.no_grad():\n    for X_batch, _ in test_loader:\n        X_batch = X_batch.to(device)\n        output = model(X_batch)\n        y_pred.append(output.cpu().numpy())\ny_pred = np.concatenate(y_pred, axis=0)\n\n# Đánh giá\nmetrics = evaluate_model(y_test.numpy(), y_pred, threshold=1.0)\nprint(\"Evaluation Metrics:\", metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:17:24.410440Z","iopub.execute_input":"2025-05-01T05:17:24.411047Z","iopub.status.idle":"2025-05-01T05:17:27.246607Z","shell.execute_reply.started":"2025-05-01T05:17:24.411025Z","shell.execute_reply":"2025-05-01T05:17:27.246015Z"}},"outputs":[{"name":"stdout","text":"Evaluation Metrics: {'rmse': 0.97147405, 'corr': 0.40911798474793076, 'accuracy': 0.9789460905349794, 'csi': 0.15947624367483734, 'far': 0.29938650306748466, 'hss': 0.26837819154232984, 'ets': 0.15498660864139285}\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Vẽ scatter plot\nplot_scatter(y_test.numpy(), y_pred, os.path.join(OUTPUT_PATH, 'scatter_plot.png'))\n\n# Vẽ bản đồ cho mẫu đầu tiên\nplot_rainfall_map(y_test[0].numpy(), y_pred[0], os.path.join(OUTPUT_PATH, 'rainfall_map.png'))\n\n# Lưu bản đồ dự đoán dưới dạng GeoTIFF\nsave_geotiff(y_pred[0], os.path.join(OUTPUT_PATH, 'predicted_rainfall.tif'),\n             precip_files[common_datetimes[-1]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T05:17:27.247332Z","iopub.execute_input":"2025-05-01T05:17:27.247563Z","iopub.status.idle":"2025-05-01T05:17:38.956212Z","shell.execute_reply.started":"2025-05-01T05:17:27.247538Z","shell.execute_reply":"2025-05-01T05:17:38.955638Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/110m_physical/ne_110m_coastline.zip\n  warnings.warn(f'Downloading: {url}', DownloadWarning)\n/usr/local/lib/python3.11/dist-packages/cartopy/io/__init__.py:241: DownloadWarning: Downloading: https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_boundary_lines_land.zip\n  warnings.warn(f'Downloading: {url}', DownloadWarning)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}