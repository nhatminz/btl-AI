{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11237152,"sourceType":"datasetVersion","datasetId":7020161}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install GDAL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:01.956859Z","iopub.execute_input":"2025-05-01T09:05:01.957269Z","iopub.status.idle":"2025-05-01T09:05:04.946238Z","shell.execute_reply.started":"2025-05-01T09:05:01.957245Z","shell.execute_reply":"2025-05-01T09:05:04.945215Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: GDAL in /usr/local/lib/python3.11/dist-packages (3.6.4)\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom osgeo import gdal\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset, WeightedRandomSampler\nfrom scipy.interpolate import griddata\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nimport glob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:04.947907Z","iopub.execute_input":"2025-05-01T09:05:04.948220Z","iopub.status.idle":"2025-05-01T09:05:04.953935Z","shell.execute_reply.started":"2025-05-01T09:05:04.948197Z","shell.execute_reply":"2025-05-01T09:05:04.953186Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:04.954755Z","iopub.execute_input":"2025-05-01T09:05:04.955034Z","iopub.status.idle":"2025-05-01T09:05:04.979512Z","shell.execute_reply.started":"2025-05-01T09:05:04.955010Z","shell.execute_reply":"2025-05-01T09:05:04.978938Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# Đặt seed để tái lập kết quả\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Định nghĩa các hằng số và đường dẫn\nBASE_PATH = \"/kaggle/input/btl-ai/DATA_SV\"\nHIMA_PATH = os.path.join(BASE_PATH, \"Hima\")\nERA5_PATH = os.path.join(BASE_PATH, \"ERA5\")\nPRECIP_PATH = os.path.join(BASE_PATH, \"Precipitation/Radar\")\nOUTPUT_PATH = \"/kaggle/working/output/\"\nos.makedirs(OUTPUT_PATH, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:04.980756Z","iopub.execute_input":"2025-05-01T09:05:04.980976Z","iopub.status.idle":"2025-05-01T09:05:05.009080Z","shell.execute_reply.started":"2025-05-01T09:05:04.980961Z","shell.execute_reply":"2025-05-01T09:05:05.008553Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"HIMA_BANDS = ['B04B', 'B05B', 'B06B', 'B09B', 'B10B', 'B11B', 'B12B', 'B14B', 'B16B', 'I2B', 'I4B', 'IRB', 'VSB', 'WVB']  # 14 band\nERA5_PARAMS = ['CAPE', 'CIN', 'EWSS', 'IE', 'ISOR', 'KX', 'PEV', 'R250', 'R500', 'R850', 'SLHF', 'SLOR', 'SSHF', 'TCLW', 'TCW', 'TCWV', 'U250', 'U850', 'V250', 'V850']  # 20 tham số\nSELECTED_FEATURES = ['B04B', 'B10B', 'B11B', 'B16B', 'IRB', 'CAPE', 'R850', 'TCWV', 'U850', 'I2B', 'TCLW', 'TCW' ]  # Giả định các đặc trưng có tương quan cao\nHEIGHT, WIDTH = 90, 250\nHEIGHT, WIDTH = 90, 250\nin_channel = len(SELECTED_FEATURES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.010114Z","iopub.execute_input":"2025-05-01T09:05:05.010377Z","iopub.status.idle":"2025-05-01T09:05:05.023050Z","shell.execute_reply.started":"2025-05-01T09:05:05.010360Z","shell.execute_reply":"2025-05-01T09:05:05.022540Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Hàm đọc file GeoTIFF\ndef read_geotiff(file_path):\n    try:\n        ds = gdal.Open(file_path)\n        band = ds.GetRasterBand(1)\n        data = band.ReadAsArray()\n        ds = None\n        if data.shape != (HEIGHT, WIDTH):\n            print(f\"Invalid shape {data.shape} for file {file_path}, expected ({HEIGHT}, {WIDTH})\")\n            return None\n        return data\n    except Exception as e:\n        print(f\"Error reading {file_path}: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.023711Z","iopub.execute_input":"2025-05-01T09:05:05.024018Z","iopub.status.idle":"2025-05-01T09:05:05.041322Z","shell.execute_reply.started":"2025-05-01T09:05:05.023991Z","shell.execute_reply":"2025-05-01T09:05:05.040795Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Hàm phân tích thời gian từ tên file\ndef parse_datetime_from_filename(filename, data_type):\n    try:\n        if data_type == \"Hima\":\n            parts = filename.split('_')\n            if len(parts) < 2:\n                return None\n            time_part = parts[1].split('_TB.tif')[0]\n            time_part = time_part.replace('.Z', '')\n            dt = datetime.strptime(time_part, '%Y%m%d%H%M')\n        elif data_type == \"ERA5\":\n            parts = filename.split('_')\n            if len(parts) < 2:\n                return None\n            time_part = parts[1].replace('.tif', '')\n            dt = datetime.strptime(time_part, '%Y%m%d%H%M%S')\n        elif data_type == \"Radar\":\n            time_part = filename.split('_')[1].replace('.tif', '')\n            dt = datetime.strptime(time_part, '%Y%m%d%H%M%S')\n        else:\n            return None\n        return dt.replace(minute=0, second=0, microsecond=0)\n    except Exception as e:\n        global error_count\n        if error_count < 5:\n            print(f\"Error parsing datetime from {filename} (type {data_type}): {e}\")\n            error_count += 1\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.042043Z","iopub.execute_input":"2025-05-01T09:05:05.042241Z","iopub.status.idle":"2025-05-01T09:05:05.062503Z","shell.execute_reply.started":"2025-05-01T09:05:05.042225Z","shell.execute_reply":"2025-05-01T09:05:05.061999Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"error_count = 0\n\n# Hàm thu thập file\ndef collect_files(base_path, expected_subdirs=None, data_type=None):\n    files_dict = {}\n    file_count = 0\n    for root, dirs, files in os.walk(base_path):\n        for file in files:\n            if file.endswith('.tif'):\n                file_path = os.path.join(root, file)\n                dt = parse_datetime_from_filename(file, data_type)\n                if dt is None:\n                    continue\n                file_count += 1\n                if expected_subdirs:\n                    subdir = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(file_path)))))\n                    if dt not in files_dict:\n                        files_dict[dt] = {}\n                    files_dict[dt][subdir] = file_path\n                else:\n                    files_dict[dt] = file_path\n    print(f\"Found {file_count} files in {base_path}\")\n    return files_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.063158Z","iopub.execute_input":"2025-05-01T09:05:05.063390Z","iopub.status.idle":"2025-05-01T09:05:05.082329Z","shell.execute_reply.started":"2025-05-01T09:05:05.063375Z","shell.execute_reply":"2025-05-01T09:05:05.081821Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"def preprocess_data(data, data_type):\n    if data is None:\n        return None\n    # Xử lý giá trị không hợp lệ bằng nội suy\n    if np.any(np.isinf(data) | np.isnan(data) | (data == -9999)):\n        mask = np.isinf(data) | np.isnan(data) | (data == -9999)\n        x, y = np.indices(data.shape)\n        valid_points = np.column_stack((x[~mask], y[~mask]))\n        valid_values = data[~mask]\n        invalid_points = np.column_stack((x[mask], y[mask]))\n        if len(valid_values) > 0:\n            interpolated_values = griddata(valid_points, valid_values, invalid_points, method='nearest')\n            data[mask] = interpolated_values\n        else:\n            data[mask] = 0\n    if data_type == \"Radar\":\n        data = np.maximum(data, 0)  # Đảm bảo không có giá trị âm\n    else:\n        # Min-max scaling cho Himawari và ERA5\n        data_min, data_max = np.min(data), np.max(data)\n        if data_max > data_min:\n            data = (data - data_min) / (data_max - data_min)\n        else:\n            data = np.zeros_like(data)\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.083348Z","iopub.execute_input":"2025-05-01T09:05:05.083634Z","iopub.status.idle":"2025-05-01T09:05:05.106080Z","shell.execute_reply.started":"2025-05-01T09:05:05.083612Z","shell.execute_reply":"2025-05-01T09:05:05.105525Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# Hàm tạo chuỗi thời gian t-4 đến t\ndef create_time_sequences(hima_files, era5_files, precip_files, common_datetimes):\n    X, y = [], []\n    for i in range(4, len(common_datetimes)):\n        dt = common_datetimes[i]\n        # Kiểm tra tính liên tục của 5 khung\n        valid_sequence = True\n        for j in range(1, 5):\n            if common_datetimes[i-j] != dt - timedelta(hours=j):\n                valid_sequence = False\n                break\n        if not valid_sequence:\n            continue\n\n        # Tạo chuỗi 5 khung\n        sequence = []\n        for j in range(5):\n            dt_j = common_datetimes[i-j]\n            # Đọc Himawari (chỉ các band được chọn)\n            hima_data = []\n            for band in [b for b in HIMA_BANDS if b in SELECTED_FEATURES]:\n                file_path = hima_files.get(dt_j, {}).get(band)\n                if not file_path:\n                    valid_sequence = False\n                    break\n                data = read_geotiff(file_path)\n                data = preprocess_data(data, \"Hima\")\n                if data is None:\n                    valid_sequence = False\n                    break\n                hima_data.append(data)\n            if not valid_sequence:\n                break\n\n            # Đọc ERA5 (chỉ các tham số được chọn)\n            era5_data = []\n            for param in [p for p in ERA5_PARAMS if p in SELECTED_FEATURES]:\n                file_path = era5_files.get(dt_j, {}).get(param)\n                if not file_path:\n                    valid_sequence = False\n                    break\n                data = read_geotiff(file_path)\n                data = preprocess_data(data, \"ERA5\")\n                if data is None:\n                    valid_sequence = False\n                    break\n                era5_data.append(data)\n            if not valid_sequence:\n                break\n\n            # Kết hợp Himawari và ERA5\n            combined = np.concatenate([np.stack(hima_data, axis=-1), np.stack(era5_data, axis=-1)], axis=-1)  # (90, 250, 10)\n            sequence.append(combined)\n        if not valid_sequence:\n            continue\n\n        # Đọc radar (ground truth)\n        radar_file = precip_files.get(dt)\n        if not radar_file:\n            continue\n        radar_data = read_geotiff(radar_file)\n        radar_data = preprocess_data(radar_data, \"Radar\")\n        if radar_data is None:\n            continue\n\n        sequence = np.stack(sequence, axis=0)  # (5, 90, 250, 10)\n        X.append(sequence)\n        y.append(radar_data)  # (90, 250)\n\n    X = np.array(X)\n    y = np.array(y)\n    # Chuyển đổi định dạng để kênh nằm trước chiều không gian\n    X = X.transpose(0, 1, 4, 2, 3)  # (samples, 5, 10, 90, 250)\n    return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.108686Z","iopub.execute_input":"2025-05-01T09:05:05.108896Z","iopub.status.idle":"2025-05-01T09:05:05.124453Z","shell.execute_reply.started":"2025-05-01T09:05:05.108880Z","shell.execute_reply":"2025-05-01T09:05:05.123943Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Định nghĩa lớp ConvLSTMCell tùy chỉnh\nclass ConvLSTMCell(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, padding):\n        super(ConvLSTMCell, self).__init__()\n        self.out_channels = out_channels\n        self.conv = nn.Conv2d(\n            in_channels + out_channels, 4 * out_channels, kernel_size,\n            padding=padding, bias=True\n        )\n\n    def forward(self, x, h_prev, c_prev):\n        combined = torch.cat([x, h_prev], dim=1)\n        conv_out = self.conv(combined)\n        i, f, o, g = torch.chunk(conv_out, 4, dim=1)\n        i = torch.sigmoid(i)\n        f = torch.sigmoid(f)\n        o = torch.sigmoid(o)\n        g = torch.tanh(g)\n        c_next = f * c_prev + i * g\n        h_next = o * torch.tanh(c_next)\n        return h_next, c_next","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.125027Z","iopub.execute_input":"2025-05-01T09:05:05.125186Z","iopub.status.idle":"2025-05-01T09:05:05.152751Z","shell.execute_reply.started":"2025-05-01T09:05:05.125173Z","shell.execute_reply":"2025-05-01T09:05:05.152183Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# Định nghĩa lớp ConvLSTM2d\nclass ConvLSTM2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, padding):\n        super(ConvLSTM2d, self).__init__()\n        self.cell = ConvLSTMCell(in_channels, out_channels, kernel_size, padding)\n\n    def forward(self, x):\n        if len(x.size()) == 5:\n            batch, seq_len, channels, height, width = x.size()\n            is_sequence = True\n        elif len(x.size()) == 4:\n            batch, channels, height, width = x.size()\n            seq_len = 1\n            x = x.unsqueeze(1)\n            is_sequence = False\n        else:\n            raise ValueError(f\"Expected 4 or 5 dimensions, got {len(x.size())}\")\n\n        out_channels = self.cell.out_channels\n        h = torch.zeros(batch, out_channels, height, width, device=x.device)\n        c = torch.zeros(batch, out_channels, height, width, device=x.device)\n        outputs = []\n        for t in range(seq_len):\n            x_t = x[:, t, :, :, :]\n            h, c = self.cell(x_t, h, c)\n            outputs.append(h)\n        output = outputs[-1] if is_sequence else h\n        return output, (h, c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.153430Z","iopub.execute_input":"2025-05-01T09:05:05.153732Z","iopub.status.idle":"2025-05-01T09:05:05.172974Z","shell.execute_reply.started":"2025-05-01T09:05:05.153712Z","shell.execute_reply":"2025-05-01T09:05:05.172422Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Hàm huấn luyện (giữ weighted loss để xử lý dữ liệu không cân bằng)\ndef train_model(model, train_loader, val_loader, epochs=30, patience=7):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    criterion = nn.MSELoss(reduction='none')\n    optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Giảm lr để ổn định\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n    best_loss = float('inf')\n    patience_counter = 0\n    best_model_state = None\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n        for X_batch, y_batch in train_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            optimizer.zero_grad()\n            output = model(X_batch)\n            weights = torch.where(y_batch > 0, torch.tensor(10.0, device=device), torch.tensor(1.0, device=device))\n            loss = (criterion(output, y_batch) * weights).mean()\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * X_batch.size(0)\n        train_loss /= len(train_loader.dataset)\n\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                output = model(X_batch)\n                weights = torch.where(y_batch > 0, torch.tensor(10.0, device=device), torch.tensor(1.0, device=device))\n                loss = (criterion(output, y_batch) * weights).mean()\n                val_loss += loss.item() * X_batch.size(0)\n            val_loss /= len(val_loader.dataset)\n\n        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, LR: {optimizer.param_groups[0]['lr']}\")\n        scheduler.step(val_loss)\n\n        if val_loss < best_loss:\n            best_loss = val_loss\n            best_model_state = model.state_dict()\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(\"Early stopping\")\n                break\n\n    model.load_state_dict(best_model_state)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.173631Z","iopub.execute_input":"2025-05-01T09:05:05.173938Z","iopub.status.idle":"2025-05-01T09:05:05.198696Z","shell.execute_reply.started":"2025-05-01T09:05:05.173909Z","shell.execute_reply":"2025-05-01T09:05:05.198180Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"# import torch.optim as optim\n\n# # Định nghĩa lớp SpatialAttention\n# class SpatialAttention(nn.Module):\n#     def __init__(self, in_channels):\n#         super(SpatialAttention, self).__init__()\n#         self.conv1 = nn.Conv2d(2, in_channels // 8, kernel_size=1)  # Đầu vào là 2 kênh từ avg và max\n#         self.conv2 = nn.Conv2d(in_channels // 8, in_channels, kernel_size=1)\n#         self.sigmoid = nn.Sigmoid()\n\n#     def forward(self, x):\n#         avg_out = torch.mean(x, dim=1, keepdim=True)  # Trung bình theo kênh\n#         max_out, _ = torch.max(x, dim=1, keepdim=True)  # Tối đa theo kênh\n#         out = torch.cat([avg_out, max_out], dim=1)  # Ghép thành 2 kênh\n#         out = self.conv1(out)\n#         out = self.conv2(out)\n#         return self.sigmoid(out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.199366Z","iopub.execute_input":"2025-05-01T09:05:05.199531Z","iopub.status.idle":"2025-05-01T09:05:05.223890Z","shell.execute_reply.started":"2025-05-01T09:05:05.199518Z","shell.execute_reply":"2025-05-01T09:05:05.223348Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# Định nghĩa mô hình ConvLSTM không có SpatialAttention\nclass ConvLSTMModel(nn.Module):\n    def __init__(self, in_channels=in_channel, hidden_channels=64, kernel_size=5):\n        super(ConvLSTMModel, self).__init__()\n        self.convlstm1 = ConvLSTM2d(in_channels, hidden_channels, kernel_size, padding=(kernel_size//2))\n        self.bn1 = nn.BatchNorm2d(hidden_channels)\n        self.convlstm2 = ConvLSTM2d(hidden_channels, 32, kernel_size, padding=(kernel_size//2))\n        self.bn2 = nn.BatchNorm2d(32)\n        self.dropout = nn.Dropout(0.2)\n        self.conv = nn.Conv2d(32, 1, kernel_size=3, padding=1)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x, _ = self.convlstm1(x)\n        x = self.bn1(x)\n        x, _ = self.convlstm2(x)\n        x = self.bn2(x)\n        x = self.dropout(x)\n        x = self.conv(x)\n        x = self.relu(x)\n        return x.squeeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.224501Z","iopub.execute_input":"2025-05-01T09:05:05.224740Z","iopub.status.idle":"2025-05-01T09:05:05.248967Z","shell.execute_reply.started":"2025-05-01T09:05:05.224723Z","shell.execute_reply":"2025-05-01T09:05:05.248408Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"def evaluate_model(y_true, y_pred, threshold=1.0):\n    rmse = np.sqrt(mean_squared_error(y_true.flatten(), y_pred.flatten()))\n    corr = np.corrcoef(y_true.flatten(), y_pred.flatten())[0, 1] if np.std(y_true) > 0 and np.std(y_pred) > 0 else 0\n\n    y_true_bin = (y_true > threshold).astype(int)\n    y_pred_bin = (y_pred > threshold).astype(int)\n    hits = np.sum((y_true_bin == 1) & (y_pred_bin == 1))\n    misses = np.sum((y_true_bin == 1) & (y_pred_bin == 0))\n    false_alarms = np.sum((y_true_bin == 0) & (y_pred_bin == 1))\n    true_negatives = np.sum((y_true_bin == 0) & (y_pred_bin == 0))\n    total = hits + misses + false_alarms + true_negatives\n\n    accuracy = (hits + true_negatives) / total if total > 0 else 0\n    csi = hits / (hits + misses + false_alarms) if (hits + misses + false_alarms) > 0 else 0\n    far = false_alarms / (hits + false_alarms) if (hits + false_alarms) > 0 else 0\n    hss = (2 * (hits * true_negatives - misses * false_alarms)) / \\\n          ((hits + misses) * (misses + true_negatives) + (hits + false_alarms) * (false_alarms + true_negatives)) \\\n          if ((hits + misses) * (misses + true_negatives) + (hits + false_alarms) * (false_alarms + true_negatives)) > 0 else 0\n    ets = ((hits - ((hits + misses) * (hits + false_alarms) / total)) / \\\n           (hits + misses + false_alarms - ((hits + misses) * (hits + false_alarms) / total))) \\\n          if (hits + misses + false_alarms - ((hits + misses) * (hits + false_alarms) / total)) > 0 else 0\n\n    return {'rmse': rmse, 'corr': corr, 'accuracy': accuracy, 'csi': csi, 'far': far, 'hss': hss, 'ets': ets}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.249584Z","iopub.execute_input":"2025-05-01T09:05:05.249846Z","iopub.status.idle":"2025-05-01T09:05:05.270727Z","shell.execute_reply.started":"2025-05-01T09:05:05.249810Z","shell.execute_reply":"2025-05-01T09:05:05.270221Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"# Hàm vẽ scatter plot\ndef plot_scatter(y_true, y_pred, output_path):\n    plt.figure(figsize=(8, 6))\n    plt.scatter(y_true.flatten(), y_pred.flatten(), alpha=0.5)\n    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n    plt.xlabel('Ground Truth (mm/h)')\n    plt.ylabel('Predicted (mm/h)')\n    plt.title('Scatter Plot: Predicted vs Ground Truth')\n    plt.savefig(output_path)\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.271433Z","iopub.execute_input":"2025-05-01T09:05:05.271667Z","iopub.status.idle":"2025-05-01T09:05:05.298054Z","shell.execute_reply.started":"2025-05-01T09:05:05.271643Z","shell.execute_reply":"2025-05-01T09:05:05.297469Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# Hàm hiển thị bản đồ\ndef plot_rainfall_map(y_true, y_pred, output_path):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5), subplot_kw={'projection': ccrs.PlateCarree()})\n    ax1.set_title('Ground Truth')\n    ax2.set_title('Prediction')\n    for ax, data in [(ax1, y_true), (ax2, y_pred)]:\n        ax.coastlines()\n        ax.add_feature(cfeature.BORDERS)\n        im = ax.imshow(data, cmap='Blues', origin='upper', transform=ccrs.PlateCarree())\n        plt.colorbar(im, ax=ax, label='Rainfall (mm/h)')\n    plt.savefig(output_path)\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.298727Z","iopub.execute_input":"2025-05-01T09:05:05.299208Z","iopub.status.idle":"2025-05-01T09:05:05.314854Z","shell.execute_reply.started":"2025-05-01T09:05:05.299190Z","shell.execute_reply":"2025-05-01T09:05:05.314125Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# Hàm lưu GeoTIFF\ndef save_geotiff(data, output_path, reference_file):\n    ds = gdal.Open(reference_file)\n    driver = gdal.GetDriverByName('GTiff')\n    out_ds = driver.Create(output_path, WIDTH, HEIGHT, 1, gdal.GDT_Float32)\n    out_ds.SetGeoTransform(ds.GetGeoTransform())\n    out_ds.SetProjection(ds.GetProjection())\n    out_band = out_ds.GetRasterBand(1)\n    out_band.WriteArray(data)\n    out_band.FlushCache()\n    out_ds = None\n    ds = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.315541Z","iopub.execute_input":"2025-05-01T09:05:05.315710Z","iopub.status.idle":"2025-05-01T09:05:05.338149Z","shell.execute_reply.started":"2025-05-01T09:05:05.315697Z","shell.execute_reply":"2025-05-01T09:05:05.337578Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# Bắt đầu chương trình\nprint(\"Collecting Himawari files...\")\nhima_files = {}\nfor band in HIMA_BANDS:\n    band_path = os.path.join(HIMA_PATH, band)\n    if not os.path.exists(band_path):\n        print(f\"Directory not found: {band_path}\")\n        continue\n    band_files = collect_files(band_path, expected_subdirs=HIMA_BANDS, data_type=\"Hima\")\n    for dt, paths in band_files.items():\n        if dt not in hima_files:\n            hima_files[dt] = {}\n        hima_files[dt][band] = paths[band]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:05.338910Z","iopub.execute_input":"2025-05-01T09:05:05.339548Z","iopub.status.idle":"2025-05-01T09:05:27.175199Z","shell.execute_reply.started":"2025-05-01T09:05:05.339525Z","shell.execute_reply":"2025-05-01T09:05:27.174545Z"}},"outputs":[{"name":"stdout","text":"Collecting Himawari files...\nFound 1438 files in /kaggle/input/btl-ai/DATA_SV/Hima/B04B\nFound 1361 files in /kaggle/input/btl-ai/DATA_SV/Hima/B05B\nFound 1158 files in /kaggle/input/btl-ai/DATA_SV/Hima/B06B\nFound 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B09B\nFound 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B10B\nFound 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B11B\nFound 2777 files in /kaggle/input/btl-ai/DATA_SV/Hima/B12B\nFound 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/B14B\nFound 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/B16B\nFound 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/I2B\nFound 2673 files in /kaggle/input/btl-ai/DATA_SV/Hima/I4B\nFound 2776 files in /kaggle/input/btl-ai/DATA_SV/Hima/IRB\nFound 1448 files in /kaggle/input/btl-ai/DATA_SV/Hima/VSB\nFound 2774 files in /kaggle/input/btl-ai/DATA_SV/Hima/WVB\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"print(\"Collecting ERA5 files...\")\nera5_files = {}\nfor param in ERA5_PARAMS:\n    param_path = os.path.join(ERA5_PATH, param)\n    if not os.path.exists(param_path):\n        print(f\"Directory not found: {param_path}\")\n        continue\n    param_files = collect_files(param_path, expected_subdirs=ERA5_PARAMS, data_type=\"ERA5\")\n    for dt, paths in param_files.items():\n        if dt not in era5_files:\n            era5_files[dt] = {}\n        era5_files[dt][param] = paths[param]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:05:27.175934Z","iopub.execute_input":"2025-05-01T09:05:27.176194Z","iopub.status.idle":"2025-05-01T09:06:12.277486Z","shell.execute_reply.started":"2025-05-01T09:05:27.176176Z","shell.execute_reply":"2025-05-01T09:06:12.276839Z"}},"outputs":[{"name":"stdout","text":"Collecting ERA5 files...\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/CAPE\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/CIN\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/EWSS\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/IE\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/ISOR\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/KX\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/PEV\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/R250\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/R500\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/R850\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/SLHF\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/SLOR\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/SSHF\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/TCLW\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/TCW\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/TCWV\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/U250\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/U850\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/V250\nFound 2928 files in /kaggle/input/btl-ai/DATA_SV/ERA5/V850\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"print(\"Collecting Precipitation files...\")\nprecip_files = collect_files(PRECIP_PATH, data_type=\"Radar\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:06:12.278220Z","iopub.execute_input":"2025-05-01T09:06:12.278470Z","iopub.status.idle":"2025-05-01T09:06:14.001179Z","shell.execute_reply.started":"2025-05-01T09:06:12.278450Z","shell.execute_reply":"2025-05-01T09:06:14.000369Z"}},"outputs":[{"name":"stdout","text":"Collecting Precipitation files...\nFound 2487 files in /kaggle/input/btl-ai/DATA_SV/Precipitation/Radar\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"# Đồng bộ thời gian\ncommon_datetimes = set(hima_files.keys()) & set(era5_files.keys()) & set(precip_files.keys())\ncommon_datetimes = sorted(list(common_datetimes))\nprint(f\"Số thời điểm đồng bộ: {len(common_datetimes)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:06:14.002058Z","iopub.execute_input":"2025-05-01T09:06:14.002449Z","iopub.status.idle":"2025-05-01T09:06:14.008680Z","shell.execute_reply.started":"2025-05-01T09:06:14.002422Z","shell.execute_reply":"2025-05-01T09:06:14.008058Z"}},"outputs":[{"name":"stdout","text":"Số thời điểm đồng bộ: 2337\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"from scipy.interpolate import griddata\n# Tạo chuỗi thời gian\nprint(\"Creating time sequences...\")\nX, y = create_time_sequences(hima_files, era5_files, precip_files, common_datetimes)\nprint(f\"X shape: {X.shape}, y shape: {y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:06:14.009371Z","iopub.execute_input":"2025-05-01T09:06:14.010114Z","iopub.status.idle":"2025-05-01T09:08:54.346312Z","shell.execute_reply.started":"2025-05-01T09:06:14.010089Z","shell.execute_reply":"2025-05-01T09:08:54.345458Z"}},"outputs":[{"name":"stdout","text":"Creating time sequences...\nX shape: (720, 5, 12, 90, 250), y shape: (720, 90, 250)\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"### Data augumentation","metadata":{}},{"cell_type":"code","source":"# Chia dữ liệu thành train, val, test\nX_train_full, X_temp, y_train_full, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\nprint(f\"Train: {X_train_full.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:08:54.347305Z","iopub.execute_input":"2025-05-01T09:08:54.348166Z","iopub.status.idle":"2025-05-01T09:08:55.726144Z","shell.execute_reply.started":"2025-05-01T09:08:54.348136Z","shell.execute_reply":"2025-05-01T09:08:55.725296Z"}},"outputs":[{"name":"stdout","text":"Train: (504, 5, 12, 90, 250), Val: (108, 5, 12, 90, 250), Test: (108, 5, 12, 90, 250)\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"# Chuyển sang tensor\nX_train_full = torch.tensor(X_train_full, dtype=torch.float32)\ny_train_full = torch.tensor(y_train_full, dtype=torch.float32)\nX_val = torch.tensor(X_val, dtype=torch.float32)\ny_val = torch.tensor(y_val, dtype=torch.float32)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.float32)\n\n# Tính tỷ lệ pixel mưa trong mỗi mẫu\nrain_indices = []\nno_rain_indices = []\nthreshold_ratio = 0.05  # Ngưỡng: ít nhất 5% pixel có mưa\ntotal_pixels = 90 * 250  # Số pixel trong mỗi mẫu\n\nfor i in range(len(X_train_full)):\n    rain_pixels = torch.sum(y_train_full[i] > 0).item()\n    rain_ratio = rain_pixels / total_pixels\n    if rain_ratio >= threshold_ratio:\n        rain_indices.append(i)\n    else:\n        no_rain_indices.append(i)\n\nprint(f\"Number of samples with rain in train set: {len(rain_indices)}\")\nprint(f\"Number of samples without rain in train set: {len(no_rain_indices)}\")\n\n\n# Tính trọng số cho WeightedRandomSampler\nweights = torch.zeros(len(X_train_full))\noversample_factor = 5  # Giảm từ 10 xuống 5 để tiết kiệm RAM\nfor i in rain_indices:\n    weights[i] = oversample_factor * (len(no_rain_indices) / len(rain_indices))  # Tăng trọng số cho mẫu có mưa\nfor i in no_rain_indices:\n    weights[i] = 1.0  # Trọng số mặc định cho mẫu không mưa\n\n# Tạo sampler\ntrain_sampler = WeightedRandomSampler(weights=weights, num_samples=len(X_train_full), replacement=True)\n\n# Tạo TensorDataset\ntrain_dataset = TensorDataset(X_train_full, y_train_full)\nval_dataset = TensorDataset(X_val, y_val)\ntest_dataset = TensorDataset(X_test, y_test)\n\n# Tạo DataLoader với sampler cho tập train\ntrain_loader = DataLoader(train_dataset, batch_size=8, sampler=train_sampler)\nval_loader = DataLoader(val_dataset, batch_size=8)\ntest_loader = DataLoader(test_dataset, batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:08:55.727149Z","iopub.execute_input":"2025-05-01T09:08:55.727741Z","iopub.status.idle":"2025-05-01T09:08:57.367855Z","shell.execute_reply.started":"2025-05-01T09:08:55.727710Z","shell.execute_reply":"2025-05-01T09:08:57.366928Z"}},"outputs":[{"name":"stdout","text":"Number of samples with rain in train set: 188\nNumber of samples without rain in train set: 316\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"# Khởi tạo và huấn luyện mô hình\nmodel = ConvLSTMModel().to(device)\nmodel = train_model(model, train_loader, val_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:08:57.368829Z","iopub.execute_input":"2025-05-01T09:08:57.369088Z","iopub.status.idle":"2025-05-01T09:26:57.037567Z","shell.execute_reply.started":"2025-05-01T09:08:57.369070Z","shell.execute_reply":"2025-05-01T09:26:57.036708Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30, Train Loss: 17.7588, Val Loss: 43.1117, LR: 0.0001\nEpoch 2/30, Train Loss: 17.7262, Val Loss: 43.4238, LR: 0.0001\nEpoch 3/30, Train Loss: 22.5581, Val Loss: 43.4488, LR: 0.0001\nEpoch 4/30, Train Loss: 23.5547, Val Loss: 42.0627, LR: 0.0001\nEpoch 5/30, Train Loss: 22.8258, Val Loss: 41.8399, LR: 0.0001\nEpoch 6/30, Train Loss: 17.5843, Val Loss: 41.8889, LR: 0.0001\nEpoch 7/30, Train Loss: 18.2838, Val Loss: 41.8687, LR: 0.0001\nEpoch 8/30, Train Loss: 20.2648, Val Loss: 43.8251, LR: 0.0001\nEpoch 9/30, Train Loss: 17.4918, Val Loss: 41.6055, LR: 0.0001\nEpoch 10/30, Train Loss: 15.5867, Val Loss: 42.4865, LR: 0.0001\nEpoch 11/30, Train Loss: 15.1016, Val Loss: 41.3256, LR: 0.0001\nEpoch 12/30, Train Loss: 15.6329, Val Loss: 41.8009, LR: 0.0001\nEpoch 13/30, Train Loss: 15.0371, Val Loss: 41.9465, LR: 0.0001\nEpoch 14/30, Train Loss: 13.7249, Val Loss: 41.1826, LR: 0.0001\nEpoch 15/30, Train Loss: 15.5693, Val Loss: 41.9359, LR: 0.0001\nEpoch 16/30, Train Loss: 18.1580, Val Loss: 40.8508, LR: 0.0001\nEpoch 17/30, Train Loss: 17.3854, Val Loss: 41.1227, LR: 0.0001\nEpoch 18/30, Train Loss: 15.2390, Val Loss: 41.0017, LR: 0.0001\nEpoch 19/30, Train Loss: 14.4541, Val Loss: 40.8960, LR: 0.0001\nEpoch 20/30, Train Loss: 17.4525, Val Loss: 40.5774, LR: 0.0001\nEpoch 21/30, Train Loss: 15.9769, Val Loss: 39.3040, LR: 0.0001\nEpoch 22/30, Train Loss: 16.8120, Val Loss: 40.8172, LR: 0.0001\nEpoch 23/30, Train Loss: 14.7155, Val Loss: 39.5330, LR: 0.0001\nEpoch 24/30, Train Loss: 15.2833, Val Loss: 40.9620, LR: 0.0001\nEpoch 25/30, Train Loss: 17.5661, Val Loss: 40.3195, LR: 0.0001\nEpoch 26/30, Train Loss: 14.7731, Val Loss: 39.0298, LR: 5e-05\nEpoch 27/30, Train Loss: 11.6949, Val Loss: 38.3379, LR: 5e-05\nEpoch 28/30, Train Loss: 12.3208, Val Loss: 38.7496, LR: 5e-05\nEpoch 29/30, Train Loss: 13.1224, Val Loss: 39.3022, LR: 5e-05\nEpoch 30/30, Train Loss: 14.6863, Val Loss: 39.3036, LR: 5e-05\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"# Đánh giá trên tập kiểm thử\nmodel.eval()\ny_pred = []\nwith torch.no_grad():\n    for X_batch, _ in test_loader:\n        X_batch = X_batch.to(device)\n        output = model(X_batch)\n        y_pred.append(output.cpu().numpy())\ny_pred = np.concatenate(y_pred, axis=0)\n\n# Đánh giá\nmetrics = evaluate_model(y_test.numpy(), y_pred, threshold=0.5)\nprint(\"Evaluation Metrics:\", metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:26:57.041797Z","iopub.execute_input":"2025-05-01T09:26:57.042195Z","iopub.status.idle":"2025-05-01T09:26:59.535176Z","shell.execute_reply.started":"2025-05-01T09:26:57.042170Z","shell.execute_reply":"2025-05-01T09:26:59.534319Z"}},"outputs":[{"name":"stdout","text":"Evaluation Metrics: {'rmse': 0.9670093, 'corr': 0.4309980857215112, 'accuracy': 0.8712012345679012, 'csi': 0.15011092676118296, 'far': 0.8403013704961982, 'hss': 0.220457084379325, 'ets': 0.12388410666816273}\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"# Vẽ scatter plot\nplot_scatter(y_test.numpy(), y_pred, os.path.join(OUTPUT_PATH, 'scatter_plot.png'))\n\n# Vẽ bản đồ cho mẫu đầu tiên\nplot_rainfall_map(y_test[0].numpy(), y_pred[0], os.path.join(OUTPUT_PATH, 'rainfall_map.png'))\n\n# Lưu bản đồ dự đoán dưới dạng GeoTIFF\nsave_geotiff(y_pred[0], os.path.join(OUTPUT_PATH, 'predicted_rainfall.tif'),\n             precip_files[common_datetimes[-1]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T09:26:59.536095Z","iopub.execute_input":"2025-05-01T09:26:59.536672Z","iopub.status.idle":"2025-05-01T09:27:10.700183Z","shell.execute_reply.started":"2025-05-01T09:26:59.536641Z","shell.execute_reply":"2025-05-01T09:27:10.699613Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}